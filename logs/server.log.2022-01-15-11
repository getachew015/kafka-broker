[2022-01-15 09:18:44,115] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,119] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,135] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,136] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,141] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 09:18:44,141] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 09:18:44,151] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 09:18:44,151] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-01-15 09:18:44,161] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-01-15 09:18:44,184] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,185] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,187] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,187] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:18:44,188] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-01-15 09:18:44,193] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 09:18:44,214] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,214] INFO Server environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,215] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,215] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,216] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,216] INFO Server environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,221] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,228] INFO Server environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,230] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,232] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,233] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,235] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,237] INFO Server environment:user.name=Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,244] INFO Server environment:user.home=C:\Users\Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,245] INFO Server environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,248] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,250] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,252] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,258] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,259] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,261] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 snapdir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:18:44,325] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-01-15 09:18:44,343] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 09:18:44,363] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 09:18:44,415] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-01-15 09:18:44,423] INFO Reading snapshot C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.18e (org.apache.zookeeper.server.persistence.FileSnap)
[2022-01-15 09:18:44,517] INFO Snapshotting: 0x1ae to C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.1ae (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 09:18:44,576] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-01-15 09:18:44,590] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2022-01-15 09:19:00,649] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 09:19:01,299] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 09:19:01,410] INFO starting (kafka.server.KafkaServer)
[2022-01-15 09:19:01,411] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 09:19:01,437] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:19:01,456] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,456] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,456] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,456] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,457] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,457] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,459] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,460] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,460] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,462] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,471] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,473] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,474] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,476] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,477] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,479] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,482] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,487] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,492] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:01,523] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 09:19:01,537] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:19:01,541] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:19:01,565] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:19:01,579] INFO Socket connection established, initiating session, client: /127.0.0.1:58672, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:19:01,609] INFO Creating new log file: log.1af (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-01-15 09:19:01,633] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003bffc8880000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:19:01,643] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:19:01,866] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:19:02,101] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 09:19:02,111] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 09:19:02,128] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.InconsistentBrokerIdException: Configured broker.id 1 doesn't match stored broker.id Some(0) in meta.properties. If you moved your data, make sure your configured broker.id matches. If you intend to create a new broker, you should remove all data in your data directories (log.dirs).
	at kafka.server.KafkaServer.getOrGenerateBrokerId(KafkaServer.scala:793)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:221)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-01-15 09:19:02,131] INFO shutting down (kafka.server.KafkaServer)
[2022-01-15 09:19:02,141] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:19:02,143] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:19:02,143] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:19:02,148] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:19:02,270] INFO Session: 0x1003bffc8880000 closed (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:19:02,271] INFO EventThread shut down for session: 0x1003bffc8880000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:19:02,279] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:19:02,298] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:19:02,300] INFO shut down completed (kafka.server.KafkaServer)
[2022-01-15 09:19:02,304] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-01-15 09:19:02,307] INFO shutting down (kafka.server.KafkaServer)
[2022-01-15 09:33:59,056] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,059] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,071] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,071] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,074] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 09:33:59,075] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 09:33:59,075] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 09:33:59,075] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-01-15 09:33:59,081] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-01-15 09:33:59,099] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,100] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,102] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,102] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 09:33:59,103] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-01-15 09:33:59,107] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 09:33:59,122] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,123] INFO Server environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,123] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,123] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,124] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,124] INFO Server environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,127] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,128] INFO Server environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,129] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,131] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,143] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,145] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,146] INFO Server environment:user.name=Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,147] INFO Server environment:user.home=C:\Users\Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,149] INFO Server environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,150] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,153] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,156] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,160] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,161] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,164] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 snapdir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:33:59,215] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-01-15 09:33:59,222] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 09:33:59,229] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 09:33:59,258] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-01-15 09:33:59,265] INFO Reading snapshot C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.1ae (org.apache.zookeeper.server.persistence.FileSnap)
[2022-01-15 09:33:59,333] INFO Snapshotting: 0x1be to C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.1be (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 09:33:59,369] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-01-15 09:33:59,393] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2022-01-15 09:34:14,133] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 09:34:14,745] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 09:34:14,861] INFO starting (kafka.server.KafkaServer)
[2022-01-15 09:34:14,862] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 09:34:14,892] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:14,905] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,905] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,905] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,906] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,906] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,907] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,911] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,912] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,914] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,917] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,921] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,923] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,938] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,940] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,943] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,945] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,947] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,950] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,961] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:14,990] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 09:34:15,004] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:15,007] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:15,021] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:15,029] INFO Socket connection established, initiating session, client: /127.0.0.1:51566, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:15,053] INFO Creating new log file: log.1bf (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-01-15 09:34:15,091] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c0dbdef0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:15,106] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:15,323] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:34:15,548] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 09:34:15,558] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 09:34:15,564] WARN No meta.properties file under dir C:\logs\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-01-15 09:34:15,680] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:34:15,704] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:34:15,765] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:15,770] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:15,775] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:15,778] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:15,809] INFO Log directory C:\logs\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-01-15 09:34:15,877] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 09:34:15,884] INFO Attempting recovery for all logs in C:\logs\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 09:34:15,906] INFO Loaded 0 logs in 28ms. (kafka.log.LogManager)
[2022-01-15 09:34:15,907] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 09:34:15,913] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 09:34:16,614] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 09:34:16,624] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-01-15 09:34:16,692] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:34:16,744] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:34:16,775] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:16,776] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:16,778] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:16,780] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:16,809] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 09:34:16,958] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 09:34:17,019] INFO Stat of the created znode at /brokers/ids/1 is: 462,462,1642260856998,1642260856998,1,0,0,72123623756726272,214,0,462
 (kafka.zk.KafkaZkClient)
[2022-01-15 09:34:17,021] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9093, czxid (broker epoch): 462 (kafka.zk.KafkaZkClient)
[2022-01-15 09:34:17,149] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:17,158] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:17,161] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:17,226] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:34:17,286] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:34:17,366] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 09:34:17,369] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:34:17,382] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:34:17,382] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 09:34:17,447] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:17,491] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 09:34:17,540] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:34:17,573] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:34:17,574] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:34:17,589] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:34:17,590] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:34:17,592] INFO Kafka startTimeMs: 1642260857576 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:34:17,596] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-01-15 09:34:17,656] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:34:37,811] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 09:34:38,413] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 09:34:38,525] INFO starting (kafka.server.KafkaServer)
[2022-01-15 09:34:38,526] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 09:34:38,556] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:38,562] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,562] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,562] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,563] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,563] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,564] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,567] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,568] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,569] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,571] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,578] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,580] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,584] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,585] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,586] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,589] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,590] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,593] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,600] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:38,640] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 09:34:38,656] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:38,663] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:38,688] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:38,705] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59626, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:38,737] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c0dbdef0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:38,746] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:38,912] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:34:39,151] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 09:34:39,159] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 09:34:39,167] WARN No meta.properties file under dir C:\logs\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-01-15 09:34:39,288] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:34:39,312] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:34:39,382] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:39,386] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:39,392] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:39,395] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:39,425] INFO Log directory C:\logs\kafka-logs2 not found, creating it. (kafka.log.LogManager)
[2022-01-15 09:34:39,490] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 09:34:39,498] INFO Attempting recovery for all logs in C:\logs\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 09:34:39,519] INFO Loaded 0 logs in 29ms. (kafka.log.LogManager)
[2022-01-15 09:34:39,520] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 09:34:39,525] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 09:34:40,203] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 09:34:40,215] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-01-15 09:34:40,285] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:34:40,340] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:34:40,372] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,375] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,378] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,379] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,404] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 09:34:40,548] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 09:34:40,579] INFO Stat of the created znode at /brokers/ids/2 is: 532,532,1642260880569,1642260880569,1,0,0,72123623756726273,214,0,532
 (kafka.zk.KafkaZkClient)
[2022-01-15 09:34:40,582] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9094, czxid (broker epoch): 532 (kafka.zk.KafkaZkClient)
[2022-01-15 09:34:40,698] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,711] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,715] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,760] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:34:40,795] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:34:40,871] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 09:34:40,874] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:34:40,884] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:34:40,886] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 09:34:40,949] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:40,983] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 09:34:41,041] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:34:41,065] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:34:41,067] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:34:41,093] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:34:41,094] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:34:41,103] INFO Kafka startTimeMs: 1642260881069 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:34:41,113] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-01-15 09:34:41,245] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:34:57,364] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 09:34:57,979] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 09:34:58,094] INFO starting (kafka.server.KafkaServer)
[2022-01-15 09:34:58,095] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 09:34:58,121] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:58,140] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,140] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,140] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,140] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,141] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,141] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,143] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,152] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,152] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,154] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,155] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,157] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,160] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,164] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,168] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,170] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,173] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,175] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,188] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:34:58,210] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 09:34:58,221] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:58,226] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:58,239] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:58,249] INFO Socket connection established, initiating session, client: /127.0.0.1:59647, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:58,267] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c0dbdef0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:34:58,283] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:34:58,438] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:34:58,649] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 09:34:58,659] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 09:34:58,667] WARN No meta.properties file under dir C:\logs\kafka-logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-01-15 09:34:58,803] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:34:58,825] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:34:58,888] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:58,893] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:58,897] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:58,901] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:34:58,924] INFO Log directory C:\logs\kafka-logs3 not found, creating it. (kafka.log.LogManager)
[2022-01-15 09:34:58,989] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 09:34:58,996] INFO Attempting recovery for all logs in C:\logs\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 09:34:59,018] INFO Loaded 0 logs in 28ms. (kafka.log.LogManager)
[2022-01-15 09:34:59,018] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 09:34:59,024] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 09:34:59,714] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 09:34:59,722] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-01-15 09:34:59,786] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:34:59,860] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:34:59,918] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:59,927] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:59,930] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:59,955] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:34:59,984] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 09:35:00,143] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 09:35:00,215] INFO Stat of the created znode at /brokers/ids/3 is: 549,549,1642260900182,1642260900182,1,0,0,72123623756726274,214,0,549
 (kafka.zk.KafkaZkClient)
[2022-01-15 09:35:00,221] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9095, czxid (broker epoch): 549 (kafka.zk.KafkaZkClient)
[2022-01-15 09:35:00,342] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:35:00,352] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:35:00,354] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:35:00,382] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:35:00,409] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:35:00,470] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 09:35:00,472] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:35:00,480] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:35:00,481] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 09:35:00,556] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:35:00,594] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 09:35:00,621] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:35:00,631] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:35:00,632] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:35:00,642] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:35:00,643] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:35:00,645] INFO Kafka startTimeMs: 1642260900632 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:35:00,651] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-01-15 09:35:00,766] INFO [broker-3-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:43:07,206] WARN Exception causing close of session 0x1003c0dbdef0001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 09:43:24,798] INFO Expiring session 0x1003c0dbdef0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:44:12,660] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 09:44:13,281] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 09:44:13,402] INFO starting (kafka.server.KafkaServer)
[2022-01-15 09:44:13,403] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 09:44:13,429] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:44:13,436] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,436] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,437] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,437] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,437] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,438] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,441] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,442] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,450] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,452] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,453] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,454] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,455] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,457] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,459] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,460] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,462] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,464] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,473] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:44:13,510] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 09:44:13,527] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:44:13,533] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:44:13,552] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:44:13,566] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:51901, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:44:13,595] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c0dbdef0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:44:13,605] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:44:13,757] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:44:13,973] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 09:44:13,982] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 09:44:14,103] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Java_Tools/kafka_2.12-2.8.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:44:14,127] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Java_Tools/kafka_2.12-2.8.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:44:14,198] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:44:14,203] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:44:14,209] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:44:14,212] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:44:14,296] INFO Loading logs from log dirs ArrayBuffer(C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:14,305] INFO Attempting recovery for all logs in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 09:44:14,422] INFO [Log partition=kafkabasics_topic-0, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 5 (kafka.log.Log)
[2022-01-15 09:44:14,427] INFO [Log partition=kafkabasics_topic-0, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,436] INFO [ProducerStateManager partition=kafkabasics_topic-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2022-01-15 09:44:14,501] INFO [Log partition=kafkabasics_topic-0, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,528] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\kafkabasics_topic-0, topic=kafkabasics_topic, partition=0, highWatermark=5, lastStableOffset=5, logStartOffset=5, logEndOffset=5) with 1 segments in 186ms (1/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:14,543] INFO [Log partition=__consumer_offsets-0, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:14,546] INFO [Log partition=__consumer_offsets-0, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,565] INFO [Log partition=__consumer_offsets-0, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,578] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (2/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:14,590] INFO [Log partition=__consumer_offsets-1, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:14,594] INFO [Log partition=__consumer_offsets-1, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,618] INFO [Log partition=__consumer_offsets-1, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,634] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (3/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:14,651] INFO [Log partition=__consumer_offsets-10, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:14,655] INFO [Log partition=__consumer_offsets-10, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,680] INFO [Log partition=__consumer_offsets-10, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,695] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 60ms (4/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:14,714] INFO [Log partition=__consumer_offsets-11, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:14,718] INFO [Log partition=__consumer_offsets-11, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,737] INFO [Log partition=__consumer_offsets-11, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,751] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (5/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:14,769] INFO [Log partition=__consumer_offsets-12, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:14,773] INFO [Log partition=__consumer_offsets-12, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,785] INFO [Log partition=__consumer_offsets-12, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,796] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (6/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:14,804] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Found file C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2022-01-15 09:44:14,806] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Deleting index files with suffix  for baseFile C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.index (kafka.log.Log)
[2022-01-15 09:44:14,813] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Found file C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2022-01-15 09:44:14,813] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Deleting index files with suffix  for baseFile C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.log (kafka.log.Log)
[2022-01-15 09:44:14,819] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Deleting index files with suffix .swap for baseFile C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.log (kafka.log.Log)
[2022-01-15 09:44:14,835] ERROR [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Could not find offset index file corresponding to log file C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2022-01-15 09:44:14,839] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,880] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2022-01-15 09:44:14,894] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:14,900] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,920] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2022-01-15 09:44:14,926] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 36 (kafka.log.Log)
[2022-01-15 09:44:14,931] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:14,936] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000036.snapshot,36)' (kafka.log.ProducerStateManager)
[2022-01-15 09:44:14,980] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 38 (kafka.log.ProducerStateManager)
[2022-01-15 09:44:15,017] INFO [Log partition=__consumer_offsets-13, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 38 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,018] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000038.snapshot,38)' (kafka.log.ProducerStateManager)
[2022-01-15 09:44:15,028] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=38) with 2 segments in 231ms (7/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,041] INFO [Log partition=__consumer_offsets-14, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,045] INFO [Log partition=__consumer_offsets-14, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,066] INFO [Log partition=__consumer_offsets-14, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,080] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 51ms (8/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,097] INFO [Log partition=__consumer_offsets-15, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,101] INFO [Log partition=__consumer_offsets-15, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,125] INFO [Log partition=__consumer_offsets-15, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,140] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 58ms (9/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,156] INFO [Log partition=__consumer_offsets-16, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,161] INFO [Log partition=__consumer_offsets-16, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,182] INFO [Log partition=__consumer_offsets-16, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,199] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 57ms (10/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,217] INFO [Log partition=__consumer_offsets-17, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,220] INFO [Log partition=__consumer_offsets-17, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,241] INFO [Log partition=__consumer_offsets-17, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,254] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (11/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,271] INFO [Log partition=__consumer_offsets-18, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,279] INFO [Log partition=__consumer_offsets-18, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,299] INFO [Log partition=__consumer_offsets-18, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,311] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (12/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,328] INFO [Log partition=__consumer_offsets-19, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,331] INFO [Log partition=__consumer_offsets-19, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,350] INFO [Log partition=__consumer_offsets-19, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,362] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (13/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,379] INFO [Log partition=__consumer_offsets-2, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,382] INFO [Log partition=__consumer_offsets-2, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,406] INFO [Log partition=__consumer_offsets-2, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,417] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (14/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,435] INFO [Log partition=__consumer_offsets-20, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,440] INFO [Log partition=__consumer_offsets-20, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,463] INFO [Log partition=__consumer_offsets-20, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,473] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (15/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,488] INFO [Log partition=__consumer_offsets-21, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,493] INFO [Log partition=__consumer_offsets-21, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,516] INFO [Log partition=__consumer_offsets-21, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,528] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (16/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,545] INFO [Log partition=__consumer_offsets-22, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,548] INFO [Log partition=__consumer_offsets-22, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,570] INFO [Log partition=__consumer_offsets-22, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,583] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (17/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,600] INFO [Log partition=__consumer_offsets-23, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,604] INFO [Log partition=__consumer_offsets-23, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,628] INFO [Log partition=__consumer_offsets-23, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,636] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 52ms (18/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,653] INFO [Log partition=__consumer_offsets-24, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,657] INFO [Log partition=__consumer_offsets-24, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,678] INFO [Log partition=__consumer_offsets-24, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,690] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (19/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,707] INFO [Log partition=__consumer_offsets-25, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,712] INFO [Log partition=__consumer_offsets-25, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,736] INFO [Log partition=__consumer_offsets-25, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,747] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (20/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,768] INFO [Log partition=__consumer_offsets-26, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,771] INFO [Log partition=__consumer_offsets-26, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,792] INFO [Log partition=__consumer_offsets-26, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,803] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (21/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,825] INFO [Log partition=__consumer_offsets-27, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,829] INFO [Log partition=__consumer_offsets-27, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,851] INFO [Log partition=__consumer_offsets-27, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,862] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 59ms (22/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,880] INFO [Log partition=__consumer_offsets-28, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,883] INFO [Log partition=__consumer_offsets-28, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,903] INFO [Log partition=__consumer_offsets-28, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,915] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 51ms (23/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,931] INFO [Log partition=__consumer_offsets-29, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,938] INFO [Log partition=__consumer_offsets-29, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,960] INFO [Log partition=__consumer_offsets-29, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:15,968] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 51ms (24/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:15,985] INFO [Log partition=__consumer_offsets-3, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:15,989] INFO [Log partition=__consumer_offsets-3, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,012] INFO [Log partition=__consumer_offsets-3, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,020] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (25/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,036] INFO [Log partition=__consumer_offsets-30, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,040] INFO [Log partition=__consumer_offsets-30, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,060] INFO [Log partition=__consumer_offsets-30, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,068] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (26/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,083] INFO [Log partition=__consumer_offsets-31, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,087] INFO [Log partition=__consumer_offsets-31, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,108] INFO [Log partition=__consumer_offsets-31, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,115] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (27/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,131] INFO [Log partition=__consumer_offsets-32, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,134] INFO [Log partition=__consumer_offsets-32, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,155] INFO [Log partition=__consumer_offsets-32, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,165] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 49ms (28/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,181] INFO [Log partition=__consumer_offsets-33, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,186] INFO [Log partition=__consumer_offsets-33, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,210] INFO [Log partition=__consumer_offsets-33, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,220] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (29/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,236] INFO [Log partition=__consumer_offsets-34, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,239] INFO [Log partition=__consumer_offsets-34, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,261] INFO [Log partition=__consumer_offsets-34, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,268] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 48ms (30/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,285] INFO [Log partition=__consumer_offsets-35, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,289] INFO [Log partition=__consumer_offsets-35, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,310] INFO [Log partition=__consumer_offsets-35, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,318] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 49ms (31/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,332] INFO [Log partition=__consumer_offsets-36, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,335] INFO [Log partition=__consumer_offsets-36, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,354] INFO [Log partition=__consumer_offsets-36, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,363] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (32/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,376] INFO [Log partition=__consumer_offsets-37, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,379] INFO [Log partition=__consumer_offsets-37, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,396] INFO [Log partition=__consumer_offsets-37, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,402] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (33/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,419] INFO [Log partition=__consumer_offsets-38, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,423] INFO [Log partition=__consumer_offsets-38, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,441] INFO [Log partition=__consumer_offsets-38, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,448] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (34/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,467] INFO [Log partition=__consumer_offsets-39, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,470] INFO [Log partition=__consumer_offsets-39, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,488] INFO [Log partition=__consumer_offsets-39, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,495] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (35/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,510] INFO [Log partition=__consumer_offsets-4, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,513] INFO [Log partition=__consumer_offsets-4, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,534] INFO [Log partition=__consumer_offsets-4, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,541] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 45ms (36/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,553] INFO [Log partition=__consumer_offsets-40, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,557] INFO [Log partition=__consumer_offsets-40, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,580] INFO [Log partition=__consumer_offsets-40, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,585] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (37/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,600] INFO [Log partition=__consumer_offsets-41, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,602] INFO [Log partition=__consumer_offsets-41, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,621] INFO [Log partition=__consumer_offsets-41, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,629] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (38/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,646] INFO [Log partition=__consumer_offsets-42, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,649] INFO [Log partition=__consumer_offsets-42, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,667] INFO [Log partition=__consumer_offsets-42, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,672] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (39/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,687] INFO [Log partition=__consumer_offsets-43, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,691] INFO [Log partition=__consumer_offsets-43, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,715] INFO [Log partition=__consumer_offsets-43, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,721] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (40/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,736] INFO [Log partition=__consumer_offsets-44, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,738] INFO [Log partition=__consumer_offsets-44, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,752] INFO [Log partition=__consumer_offsets-44, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,754] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (41/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,762] INFO [Log partition=__consumer_offsets-45, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,763] INFO [Log partition=__consumer_offsets-45, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,781] INFO [Log partition=__consumer_offsets-45, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,787] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (42/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,799] INFO [Log partition=__consumer_offsets-46, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,801] INFO [Log partition=__consumer_offsets-46, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,817] INFO [Log partition=__consumer_offsets-46, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,823] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (43/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,836] INFO [Log partition=__consumer_offsets-47, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,841] INFO [Log partition=__consumer_offsets-47, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,864] INFO [Log partition=__consumer_offsets-47, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,870] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (44/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,887] INFO [Log partition=__consumer_offsets-48, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,891] INFO [Log partition=__consumer_offsets-48, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,913] INFO [Log partition=__consumer_offsets-48, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,917] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (45/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,931] INFO [Log partition=__consumer_offsets-49, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,934] INFO [Log partition=__consumer_offsets-49, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,954] INFO [Log partition=__consumer_offsets-49, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,963] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (46/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:16,978] INFO [Log partition=__consumer_offsets-5, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:16,981] INFO [Log partition=__consumer_offsets-5, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:16,997] INFO [Log partition=__consumer_offsets-5, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,003] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (47/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:17,020] INFO [Log partition=__consumer_offsets-6, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:17,023] INFO [Log partition=__consumer_offsets-6, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,041] INFO [Log partition=__consumer_offsets-6, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,047] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (48/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:17,062] INFO [Log partition=__consumer_offsets-7, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:17,066] INFO [Log partition=__consumer_offsets-7, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,083] INFO [Log partition=__consumer_offsets-7, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,087] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (49/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:17,100] INFO [Log partition=__consumer_offsets-8, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:17,103] INFO [Log partition=__consumer_offsets-8, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,122] INFO [Log partition=__consumer_offsets-8, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,130] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (50/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:17,146] INFO [Log partition=__consumer_offsets-9, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 09:44:17,149] INFO [Log partition=__consumer_offsets-9, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,168] INFO [Log partition=__consumer_offsets-9, dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:44:17,174] INFO Completed load of Log(dir=C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (51/51 loaded in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka) (kafka.log.LogManager)
[2022-01-15 09:44:17,181] INFO Loaded 51 logs in 2884ms. (kafka.log.LogManager)
[2022-01-15 09:44:17,184] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 09:44:17,187] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 09:44:17,520] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:292)
	at java.base/java.nio.file.Files.move(Files.java:1422)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:904)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:210)
	at kafka.log.LazyIndex$IndexValue.renameTo(LazyIndex.scala:155)
	at kafka.log.LazyIndex.$anonfun$renameTo$1(LazyIndex.scala:79)
	at kafka.log.LazyIndex.renameTo(LazyIndex.scala:79)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:496)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2402)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2402)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Log.replaceSegments(Log.scala:2402)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:613)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:292)
		at java.base/java.nio.file.Files.move(Files.java:1422)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:901)
		... 20 more
[2022-01-15 09:44:17,636] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,669] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,702] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,741] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,777] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,814] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,849] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,881] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,913] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,946] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:17,977] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,008] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,018] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 09:44:18,029] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-01-15 09:44:18,042] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,073] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,112] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:44:18,116] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,151] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,182] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,201] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:44:18,214] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,235] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:44:18,239] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:44:18,244] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:44:18,245] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:44:18,250] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,282] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,285] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 09:44:18,288] WARN [ReplicaManager broker=0] Stopping serving replicas in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka (kafka.server.ReplicaManager)
[2022-01-15 09:44:18,309] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\Java_Tools\kafka_2.12-2.8.0\data\kafka. (kafka.server.ReplicaManager)
[2022-01-15 09:44:18,311] WARN Stopping serving logs in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka (kafka.log.LogManager)
[2022-01-15 09:44:18,314] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\Java_Tools\kafka_2.12-2.8.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\Java_Tools\kafka_2.12-2.8.0\data\kafka\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1181)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2684)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:675)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:454)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:566)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:538)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:537)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:537)
	at kafka.log.Cleaner.clean(LogCleaner.scala:511)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:380)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:352)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:332)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:321)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-01-15 09:44:18,317] ERROR Shutdown broker because all log dirs in C:\Java_Tools\kafka_2.12-2.8.0\data\kafka have failed (kafka.log.LogManager)
[2022-01-15 09:44:18,844] WARN Exception causing close of session 0x1003c0dbdef0003: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 09:44:36,793] INFO Expiring session 0x1003c0dbdef0003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 09:47:38,671] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 09:47:39,271] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 09:47:39,384] INFO starting (kafka.server.KafkaServer)
[2022-01-15 09:47:39,385] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 09:47:39,414] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:47:39,423] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,423] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,424] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,424] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,424] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,425] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,427] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,427] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,429] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,440] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,441] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,444] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,447] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,452] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,454] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,456] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,459] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,461] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,478] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:47:39,511] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 09:47:39,529] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:47:39,535] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:47:39,552] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:47:39,562] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:63051, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:47:39,589] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c0dbdef0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:47:39,604] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:47:39,783] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:47:40,021] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 09:47:40,034] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 09:47:40,041] WARN No meta.properties file under dir C:\logs\kafka-logs-admin\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-01-15 09:47:40,166] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:47:40,191] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:47:40,258] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:47:40,263] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:47:40,267] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:47:40,270] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:47:40,301] INFO Log directory C:\logs\kafka-logs-admin not found, creating it. (kafka.log.LogManager)
[2022-01-15 09:47:40,370] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 09:47:40,377] INFO Attempting recovery for all logs in C:\logs\kafka-logs-admin since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 09:47:40,404] INFO Loaded 0 logs in 33ms. (kafka.log.LogManager)
[2022-01-15 09:47:40,406] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 09:47:40,413] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 09:47:41,135] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 09:47:41,145] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-01-15 09:47:41,224] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:47:41,282] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:47:41,317] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,323] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,323] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,322] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,369] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 09:47:41,510] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 09:47:41,549] INFO Stat of the created znode at /brokers/ids/0 is: 583,583,1642261661535,1642261661535,1,0,0,72123623756726276,214,0,583
 (kafka.zk.KafkaZkClient)
[2022-01-15 09:47:41,552] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9092, czxid (broker epoch): 583 (kafka.zk.KafkaZkClient)
[2022-01-15 09:47:41,743] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,755] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,757] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,790] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:41,813] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:41,874] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 09:47:41,875] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:47:41,884] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:47:41,885] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 09:47:41,939] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:47:41,996] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 09:47:42,053] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:47:42,067] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:47:42,068] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:47:42,077] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:47:42,077] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:47:42,079] INFO Kafka startTimeMs: 1642261662069 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:47:42,088] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-01-15 09:47:42,285] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:47:42,401] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,412] INFO Created log for partition __consumer_offsets-0 in C:\logs\kafka-logs-admin\__consumer_offsets-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,416] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,418] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,430] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,433] INFO Created log for partition __consumer_offsets-29 in C:\logs\kafka-logs-admin\__consumer_offsets-29 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,434] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-01-15 09:47:42,435] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,446] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,451] INFO Created log for partition __consumer_offsets-48 in C:\logs\kafka-logs-admin\__consumer_offsets-48 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,452] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-01-15 09:47:42,454] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,489] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,492] INFO Created log for partition __consumer_offsets-10 in C:\logs\kafka-logs-admin\__consumer_offsets-10 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,494] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-01-15 09:47:42,498] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,522] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,525] INFO Created log for partition __consumer_offsets-45 in C:\logs\kafka-logs-admin\__consumer_offsets-45 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,527] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-01-15 09:47:42,528] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,548] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,550] INFO Created log for partition __consumer_offsets-26 in C:\logs\kafka-logs-admin\__consumer_offsets-26 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,552] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-01-15 09:47:42,553] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,581] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,586] INFO Created log for partition __consumer_offsets-7 in C:\logs\kafka-logs-admin\__consumer_offsets-7 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,587] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-01-15 09:47:42,590] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,622] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,626] INFO Created log for partition __consumer_offsets-42 in C:\logs\kafka-logs-admin\__consumer_offsets-42 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,630] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-01-15 09:47:42,634] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,663] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,667] INFO Created log for partition __consumer_offsets-4 in C:\logs\kafka-logs-admin\__consumer_offsets-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,669] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-01-15 09:47:42,672] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,697] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,701] INFO Created log for partition __consumer_offsets-23 in C:\logs\kafka-logs-admin\__consumer_offsets-23 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,702] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-01-15 09:47:42,704] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,744] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,748] INFO Created log for partition __consumer_offsets-1 in C:\logs\kafka-logs-admin\__consumer_offsets-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,753] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-01-15 09:47:42,755] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,788] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,791] INFO Created log for partition __consumer_offsets-20 in C:\logs\kafka-logs-admin\__consumer_offsets-20 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,793] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-01-15 09:47:42,795] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,830] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,834] INFO Created log for partition __consumer_offsets-39 in C:\logs\kafka-logs-admin\__consumer_offsets-39 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,835] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-01-15 09:47:42,837] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,871] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,874] INFO Created log for partition __consumer_offsets-17 in C:\logs\kafka-logs-admin\__consumer_offsets-17 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,876] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-01-15 09:47:42,878] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,901] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,904] INFO Created log for partition __consumer_offsets-36 in C:\logs\kafka-logs-admin\__consumer_offsets-36 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,905] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-01-15 09:47:42,911] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,941] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,945] INFO Created log for partition kafkabasics_topic-0 in C:\logs\kafka-logs-admin\kafkabasics_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,951] INFO [Partition kafkabasics_topic-0 broker=0] No checkpointed highwatermark is found for partition kafkabasics_topic-0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,954] INFO [Partition kafkabasics_topic-0 broker=0] Log loaded for partition kafkabasics_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:42,982] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:42,985] INFO Created log for partition __consumer_offsets-14 in C:\logs\kafka-logs-admin\__consumer_offsets-14 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:42,988] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-01-15 09:47:42,990] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,019] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,023] INFO Created log for partition __consumer_offsets-33 in C:\logs\kafka-logs-admin\__consumer_offsets-33 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,024] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-01-15 09:47:43,026] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,058] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,063] INFO Created log for partition __consumer_offsets-49 in C:\logs\kafka-logs-admin\__consumer_offsets-49 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,067] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-01-15 09:47:43,070] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,100] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,103] INFO Created log for partition __consumer_offsets-11 in C:\logs\kafka-logs-admin\__consumer_offsets-11 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,104] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-01-15 09:47:43,107] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,135] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,139] INFO Created log for partition __consumer_offsets-30 in C:\logs\kafka-logs-admin\__consumer_offsets-30 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,140] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-01-15 09:47:43,151] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,179] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,182] INFO Created log for partition __consumer_offsets-46 in C:\logs\kafka-logs-admin\__consumer_offsets-46 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,187] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-01-15 09:47:43,190] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,218] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,221] INFO Created log for partition __consumer_offsets-27 in C:\logs\kafka-logs-admin\__consumer_offsets-27 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,224] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-01-15 09:47:43,226] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,255] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,258] INFO Created log for partition __consumer_offsets-8 in C:\logs\kafka-logs-admin\__consumer_offsets-8 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,260] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-01-15 09:47:43,263] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,293] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,299] INFO Created log for partition __consumer_offsets-24 in C:\logs\kafka-logs-admin\__consumer_offsets-24 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,302] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-01-15 09:47:43,304] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,333] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,337] INFO Created log for partition __consumer_offsets-43 in C:\logs\kafka-logs-admin\__consumer_offsets-43 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,338] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-01-15 09:47:43,340] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,377] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,382] INFO Created log for partition __consumer_offsets-5 in C:\logs\kafka-logs-admin\__consumer_offsets-5 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,383] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-01-15 09:47:43,385] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,413] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,417] INFO Created log for partition __consumer_offsets-21 in C:\logs\kafka-logs-admin\__consumer_offsets-21 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,418] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-01-15 09:47:43,421] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,446] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,450] INFO Created log for partition __consumer_offsets-40 in C:\logs\kafka-logs-admin\__consumer_offsets-40 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,451] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-01-15 09:47:43,457] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,478] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,482] INFO Created log for partition __consumer_offsets-2 in C:\logs\kafka-logs-admin\__consumer_offsets-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,487] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-01-15 09:47:43,489] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,516] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,519] INFO Created log for partition __consumer_offsets-37 in C:\logs\kafka-logs-admin\__consumer_offsets-37 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,520] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-01-15 09:47:43,523] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,540] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,541] INFO Created log for partition __consumer_offsets-18 in C:\logs\kafka-logs-admin\__consumer_offsets-18 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,542] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-01-15 09:47:43,544] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,559] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,561] INFO Created log for partition __consumer_offsets-34 in C:\logs\kafka-logs-admin\__consumer_offsets-34 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,562] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-01-15 09:47:43,564] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,574] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,576] INFO Created log for partition __consumer_offsets-15 in C:\logs\kafka-logs-admin\__consumer_offsets-15 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,580] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-01-15 09:47:43,582] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,595] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,597] INFO Created log for partition __consumer_offsets-12 in C:\logs\kafka-logs-admin\__consumer_offsets-12 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,600] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-01-15 09:47:43,601] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,614] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,617] INFO Created log for partition __consumer_offsets-31 in C:\logs\kafka-logs-admin\__consumer_offsets-31 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,618] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-01-15 09:47:43,619] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,630] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,633] INFO Created log for partition __consumer_offsets-9 in C:\logs\kafka-logs-admin\__consumer_offsets-9 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,633] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-01-15 09:47:43,634] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,650] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,652] INFO Created log for partition __consumer_offsets-47 in C:\logs\kafka-logs-admin\__consumer_offsets-47 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,653] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-01-15 09:47:43,654] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,668] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,670] INFO Created log for partition __consumer_offsets-19 in C:\logs\kafka-logs-admin\__consumer_offsets-19 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,671] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-01-15 09:47:43,675] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,692] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,694] INFO Created log for partition __consumer_offsets-28 in C:\logs\kafka-logs-admin\__consumer_offsets-28 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,694] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-01-15 09:47:43,698] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,709] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,711] INFO Created log for partition __consumer_offsets-38 in C:\logs\kafka-logs-admin\__consumer_offsets-38 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,711] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-01-15 09:47:43,713] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,727] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,729] INFO Created log for partition __consumer_offsets-35 in C:\logs\kafka-logs-admin\__consumer_offsets-35 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,730] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-01-15 09:47:43,733] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,750] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,752] INFO Created log for partition __consumer_offsets-6 in C:\logs\kafka-logs-admin\__consumer_offsets-6 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,753] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-01-15 09:47:43,755] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,769] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,770] INFO Created log for partition __consumer_offsets-44 in C:\logs\kafka-logs-admin\__consumer_offsets-44 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,771] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-01-15 09:47:43,773] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,787] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,789] INFO Created log for partition __consumer_offsets-25 in C:\logs\kafka-logs-admin\__consumer_offsets-25 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,790] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-01-15 09:47:43,792] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,807] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,809] INFO Created log for partition __consumer_offsets-16 in C:\logs\kafka-logs-admin\__consumer_offsets-16 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,810] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-01-15 09:47:43,817] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,835] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,837] INFO Created log for partition __consumer_offsets-22 in C:\logs\kafka-logs-admin\__consumer_offsets-22 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,838] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-01-15 09:47:43,839] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,855] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,857] INFO Created log for partition __consumer_offsets-41 in C:\logs\kafka-logs-admin\__consumer_offsets-41 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,858] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-01-15 09:47:43,859] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,872] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,876] INFO Created log for partition __consumer_offsets-32 in C:\logs\kafka-logs-admin\__consumer_offsets-32 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,876] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-01-15 09:47:43,879] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,890] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,893] INFO Created log for partition __consumer_offsets-3 in C:\logs\kafka-logs-admin\__consumer_offsets-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,894] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-01-15 09:47:43,896] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:43,907] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:47:43,909] INFO Created log for partition __consumer_offsets-13 in C:\logs\kafka-logs-admin\__consumer_offsets-13 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:47:43,909] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-01-15 09:47:43,912] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:47:44,204] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, kafkabasics_topic-0, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:47:44,623] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,633] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,633] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,635] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,637] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,639] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,640] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,642] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,644] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,646] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,649] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,651] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 24 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,658] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,661] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 26 milliseconds, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,663] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,667] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 28 milliseconds, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,668] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,671] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 29 milliseconds, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,672] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,674] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 28 milliseconds, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,675] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,677] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 19 milliseconds, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,678] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,690] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 19 milliseconds, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,692] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,697] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,695] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 24 milliseconds, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,700] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,703] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 25 milliseconds, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,704] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,706] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 14 milliseconds, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,707] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,718] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,709] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,720] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 16 milliseconds, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,724] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,727] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,729] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,736] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,738] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,752] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,755] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,758] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 3 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,762] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,766] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,763] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,768] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,770] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,779] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,783] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,782] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,785] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,794] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,788] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 4 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,798] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,804] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,809] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,811] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,810] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,813] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,824] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,818] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,825] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,828] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,828] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 3 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,833] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,843] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,840] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,846] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,858] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,853] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 8 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,860] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,868] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,865] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 6 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,870] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,875] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,877] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,878] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,874] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 4 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,884] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,892] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,891] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 14 milliseconds, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,894] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,897] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 14 milliseconds, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,900] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,902] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,903] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,905] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,906] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,909] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,908] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,911] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,925] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,913] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 3 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,927] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,931] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,936] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,941] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,952] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,953] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,952] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,955] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,958] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,956] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,959] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,961] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,961] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 2 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,963] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,967] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,967] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,969] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,972] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,971] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,974] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,988] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,976] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 3 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,991] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:44,994] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:44,996] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,003] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:45,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,005] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,020] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:45,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,021] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 2 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,025] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:45,028] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 3 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,030] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,038] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:45,039] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,052] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:45,053] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,054] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,059] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:47:45,060] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,062] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:47:45,069] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 09:51:11,622] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 09:51:12,257] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 09:51:12,376] INFO starting (kafka.server.KafkaServer)
[2022-01-15 09:51:12,376] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 09:51:12,418] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:51:12,434] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,435] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,435] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,436] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,436] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,437] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,443] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,444] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,446] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,459] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,461] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,463] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,464] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,466] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,468] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,469] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,473] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,474] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,480] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 09:51:12,508] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 09:51:12,529] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:51:12,533] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:51:12,547] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:51:12,559] INFO Socket connection established, initiating session, client: /127.0.0.1:58725, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:51:12,585] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c0dbdef0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 09:51:12,602] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 09:51:12,769] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 09:51:12,996] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 09:51:13,008] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 09:51:13,140] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:51:13,161] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 09:51:13,225] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:51:13,229] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:51:13,233] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:51:13,238] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 09:51:13,308] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 09:51:13,315] INFO Attempting recovery for all logs in C:\logs\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 09:51:13,340] INFO Loaded 0 logs in 31ms. (kafka.log.LogManager)
[2022-01-15 09:51:13,341] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 09:51:13,348] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 09:51:14,093] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 09:51:14,103] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-01-15 09:51:14,166] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:51:14,217] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:51:14,247] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,251] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,253] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,253] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,276] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 09:51:14,432] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 09:51:14,473] INFO Stat of the created znode at /brokers/ids/2 is: 651,651,1642261874449,1642261874449,1,0,0,72123623756726277,214,0,651
 (kafka.zk.KafkaZkClient)
[2022-01-15 09:51:14,476] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9094, czxid (broker epoch): 651 (kafka.zk.KafkaZkClient)
[2022-01-15 09:51:14,614] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,626] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,628] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,656] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:51:14,684] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 09:51:14,773] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:7000,blockEndProducerId:7999) by writing to Zk with path version 8 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 09:51:14,776] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:51:14,789] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 09:51:14,789] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 09:51:14,870] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 09:51:14,926] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 09:51:14,961] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:51:14,973] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 09:51:14,975] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 09:51:14,985] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:51:14,988] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:51:14,989] INFO Kafka startTimeMs: 1642261874975 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 09:51:14,998] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-01-15 09:51:15,134] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 09:52:18,626] INFO Creating topic my_test_topic with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(1, 2, 3), 4 -> ArrayBuffer(2, 0, 3), 1 -> ArrayBuffer(3, 0, 2), 3 -> ArrayBuffer(0, 3, 1), 0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2022-01-15 09:52:18,779] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic-3) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:18,807] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:18,814] INFO Created log for partition my_test_topic-3 in C:\logs\kafka-logs-admin\my_test_topic-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:18,821] INFO [Partition my_test_topic-3 broker=0] No checkpointed highwatermark is found for partition my_test_topic-3 (kafka.cluster.Partition)
[2022-01-15 09:52:18,822] INFO [Partition my_test_topic-3 broker=0] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:18,867] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic-2) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:18,870] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:18,873] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:18,955] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:18,957] INFO Created log for partition my_test_topic-0 in C:\logs\kafka-logs-admin\my_test_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:18,960] INFO [Partition my_test_topic-0 broker=0] No checkpointed highwatermark is found for partition my_test_topic-0 (kafka.cluster.Partition)
[2022-01-15 09:52:18,962] INFO [Partition my_test_topic-0 broker=0] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:18,983] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:18,985] INFO Created log for partition my_test_topic-4 in C:\logs\kafka-logs-admin\my_test_topic-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:18,988] INFO [Partition my_test_topic-4 broker=0] No checkpointed highwatermark is found for partition my_test_topic-4 (kafka.cluster.Partition)
[2022-01-15 09:52:18,990] INFO [Partition my_test_topic-4 broker=0] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,006] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,008] INFO Created log for partition my_test_topic-1 in C:\logs\kafka-logs-admin\my_test_topic-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,009] INFO [Partition my_test_topic-1 broker=0] No checkpointed highwatermark is found for partition my_test_topic-1 (kafka.cluster.Partition)
[2022-01-15 09:52:19,010] INFO [Partition my_test_topic-1 broker=0] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,015] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic-1, my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,079] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,087] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 3 for partitions Map(my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=3, host=DESKTOP-1UO7TTD:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,092] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,098] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),0,0), my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,101] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,099] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,102] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,104] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,117] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,121] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,121] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,121] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,123] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,140] INFO Created log for partition my_test_topic-1 in C:\logs\kafka-logs3\my_test_topic-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,147] INFO [Partition my_test_topic-1 broker=3] No checkpointed highwatermark is found for partition my_test_topic-1 (kafka.cluster.Partition)
[2022-01-15 09:52:19,157] INFO Created log for partition my_test_topic-2 in C:\logs\kafka-logs1\my_test_topic-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,160] INFO [Partition my_test_topic-1 broker=3] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,164] INFO Created log for partition my_test_topic-0 in C:\logs\kafka-logs2\my_test_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,168] INFO [Partition my_test_topic-2 broker=1] No checkpointed highwatermark is found for partition my_test_topic-2 (kafka.cluster.Partition)
[2022-01-15 09:52:19,174] INFO [Partition my_test_topic-2 broker=1] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,172] INFO [Partition my_test_topic-0 broker=2] No checkpointed highwatermark is found for partition my_test_topic-0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,191] INFO [Partition my_test_topic-0 broker=2] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,257] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,261] INFO Created log for partition my_test_topic-4 in C:\logs\kafka-logs2\my_test_topic-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,263] INFO [Partition my_test_topic-4 broker=2] No checkpointed highwatermark is found for partition my_test_topic-4 (kafka.cluster.Partition)
[2022-01-15 09:52:19,266] INFO [Partition my_test_topic-4 broker=2] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,307] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition my_test_topic-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,308] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition my_test_topic-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,317] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition my_test_topic-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,354] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,356] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,358] INFO Created log for partition my_test_topic-3 in C:\logs\kafka-logs1\my_test_topic-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,360] INFO [Partition my_test_topic-3 broker=1] No checkpointed highwatermark is found for partition my_test_topic-3 (kafka.cluster.Partition)
[2022-01-15 09:52:19,359] INFO Created log for partition my_test_topic-2 in C:\logs\kafka-logs3\my_test_topic-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,368] INFO [Partition my_test_topic-3 broker=1] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,368] INFO [Partition my_test_topic-2 broker=3] No checkpointed highwatermark is found for partition my_test_topic-2 (kafka.cluster.Partition)
[2022-01-15 09:52:19,371] INFO [Partition my_test_topic-2 broker=3] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,389] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,391] INFO Created log for partition my_test_topic-0 in C:\logs\kafka-logs1\my_test_topic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,392] INFO [Partition my_test_topic-0 broker=1] No checkpointed highwatermark is found for partition my_test_topic-0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,397] INFO [Partition my_test_topic-0 broker=1] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,399] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,401] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic-3, my_test_topic-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,403] INFO Created log for partition my_test_topic-3 in C:\logs\kafka-logs3\my_test_topic-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,405] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,405] INFO [Partition my_test_topic-3 broker=3] No checkpointed highwatermark is found for partition my_test_topic-3 (kafka.cluster.Partition)
[2022-01-15 09:52:19,408] INFO [Partition my_test_topic-3 broker=3] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,419] INFO Created log for partition my_test_topic-2 in C:\logs\kafka-logs2\my_test_topic-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,424] INFO [Partition my_test_topic-2 broker=2] No checkpointed highwatermark is found for partition my_test_topic-2 (kafka.cluster.Partition)
[2022-01-15 09:52:19,433] INFO [Partition my_test_topic-2 broker=2] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,438] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,443] INFO Created log for partition my_test_topic-4 in C:\logs\kafka-logs3\my_test_topic-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,444] INFO [Partition my_test_topic-4 broker=3] No checkpointed highwatermark is found for partition my_test_topic-4 (kafka.cluster.Partition)
[2022-01-15 09:52:19,448] INFO [Partition my_test_topic-4 broker=3] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,451] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-3, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,465] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 09:52:19,484] INFO Created log for partition my_test_topic-1 in C:\logs\kafka-logs2\my_test_topic-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 09:52:19,486] INFO [Partition my_test_topic-1 broker=2] No checkpointed highwatermark is found for partition my_test_topic-1 (kafka.cluster.Partition)
[2022-01-15 09:52:19,488] INFO [Partition my_test_topic-1 broker=2] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 09:52:19,492] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,508] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,515] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,524] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,530] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,534] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,543] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,544] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,548] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,569] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,604] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition my_test_topic-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,578] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,608] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,638] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,650] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions Map(my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=3, host=DESKTOP-1UO7TTD:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,654] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,639] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,683] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,684] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,652] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,698] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,710] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,715] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,688] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,722] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,747] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,690] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 09:52:19,749] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,773] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition my_test_topic-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-01-15 09:52:19,764] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 09:52:19,758] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 10:02:33,719] INFO Creating topic my_test_topic2 with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(0), 4 -> ArrayBuffer(3), 1 -> ArrayBuffer(1), 3 -> ArrayBuffer(2), 0 -> ArrayBuffer(3)) (kafka.zk.AdminZkClient)
[2022-01-15 10:02:33,884] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic2-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:33,920] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:33,931] INFO Created log for partition my_test_topic2-1 in C:\logs\kafka-logs1\my_test_topic2-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:33,948] INFO [Partition my_test_topic2-1 broker=1] No checkpointed highwatermark is found for partition my_test_topic2-1 (kafka.cluster.Partition)
[2022-01-15 10:02:33,902] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic2-4, my_test_topic2-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:33,909] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic2-2) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:33,932] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic2-3) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:33,961] INFO [Partition my_test_topic2-1 broker=1] Log loaded for partition my_test_topic2-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:33,998] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:34,009] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:34,005] INFO Created log for partition my_test_topic2-4 in C:\logs\kafka-logs3\my_test_topic2-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:34,012] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:34,012] INFO Created log for partition my_test_topic2-2 in C:\logs\kafka-logs-admin\my_test_topic2-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:34,013] INFO [Partition my_test_topic2-4 broker=3] No checkpointed highwatermark is found for partition my_test_topic2-4 (kafka.cluster.Partition)
[2022-01-15 10:02:34,015] INFO Created log for partition my_test_topic2-3 in C:\logs\kafka-logs2\my_test_topic2-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:34,023] INFO [Partition my_test_topic2-4 broker=3] Log loaded for partition my_test_topic2-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:34,024] INFO [Partition my_test_topic2-2 broker=0] No checkpointed highwatermark is found for partition my_test_topic2-2 (kafka.cluster.Partition)
[2022-01-15 10:02:34,035] INFO [Partition my_test_topic2-2 broker=0] Log loaded for partition my_test_topic2-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:34,027] INFO [Partition my_test_topic2-3 broker=2] No checkpointed highwatermark is found for partition my_test_topic2-3 (kafka.cluster.Partition)
[2022-01-15 10:02:34,041] INFO [Partition my_test_topic2-3 broker=2] Log loaded for partition my_test_topic2-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:34,063] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:34,067] INFO Created log for partition my_test_topic2-0 in C:\logs\kafka-logs3\my_test_topic2-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:34,076] INFO [Partition my_test_topic2-0 broker=3] No checkpointed highwatermark is found for partition my_test_topic2-0 (kafka.cluster.Partition)
[2022-01-15 10:02:34,077] INFO [Partition my_test_topic2-0 broker=3] Log loaded for partition my_test_topic2-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,224] INFO Creating topic my_test_topic3 with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(1, 3), 4 -> ArrayBuffer(2, 3), 1 -> ArrayBuffer(3, 2), 3 -> ArrayBuffer(0, 1), 0 -> ArrayBuffer(2, 0)) (kafka.zk.AdminZkClient)
[2022-01-15 10:02:54,336] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic3-2) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,335] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-3) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,340] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic3-0, my_test_topic3-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,342] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic3-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,381] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,384] INFO Created log for partition my_test_topic3-2 in C:\logs\kafka-logs1\my_test_topic3-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,386] INFO [Partition my_test_topic3-2 broker=1] No checkpointed highwatermark is found for partition my_test_topic3-2 (kafka.cluster.Partition)
[2022-01-15 10:02:54,386] INFO [Partition my_test_topic3-2 broker=1] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,388] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,392] INFO Created log for partition my_test_topic3-0 in C:\logs\kafka-logs2\my_test_topic3-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,390] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,389] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,401] INFO [Partition my_test_topic3-0 broker=2] No checkpointed highwatermark is found for partition my_test_topic3-0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,405] INFO Created log for partition my_test_topic3-1 in C:\logs\kafka-logs3\my_test_topic3-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,411] INFO [Partition my_test_topic3-1 broker=3] No checkpointed highwatermark is found for partition my_test_topic3-1 (kafka.cluster.Partition)
[2022-01-15 10:02:54,403] INFO Created log for partition my_test_topic3-3 in C:\logs\kafka-logs-admin\my_test_topic3-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,406] INFO [Partition my_test_topic3-0 broker=2] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,412] INFO [Partition my_test_topic3-1 broker=3] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,420] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,428] INFO [Partition my_test_topic3-3 broker=0] No checkpointed highwatermark is found for partition my_test_topic3-3 (kafka.cluster.Partition)
[2022-01-15 10:02:54,435] INFO Created log for partition my_test_topic3-3 in C:\logs\kafka-logs1\my_test_topic3-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,433] INFO [Partition my_test_topic3-3 broker=0] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,439] INFO [Partition my_test_topic3-3 broker=1] No checkpointed highwatermark is found for partition my_test_topic3-3 (kafka.cluster.Partition)
[2022-01-15 10:02:54,444] INFO [Partition my_test_topic3-3 broker=1] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,452] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic3-3) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,470] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(my_test_topic3-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,470] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,471] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,487] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,474] INFO Created log for partition my_test_topic3-2 in C:\logs\kafka-logs3\my_test_topic3-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,477] INFO Created log for partition my_test_topic3-4 in C:\logs\kafka-logs2\my_test_topic3-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,489] INFO Created log for partition my_test_topic3-0 in C:\logs\kafka-logs-admin\my_test_topic3-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,493] INFO [Partition my_test_topic3-4 broker=2] No checkpointed highwatermark is found for partition my_test_topic3-4 (kafka.cluster.Partition)
[2022-01-15 10:02:54,490] INFO [Partition my_test_topic3-2 broker=3] No checkpointed highwatermark is found for partition my_test_topic3-2 (kafka.cluster.Partition)
[2022-01-15 10:02:54,505] INFO [Partition my_test_topic3-2 broker=3] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,504] INFO [Partition my_test_topic3-4 broker=2] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,501] INFO [Partition my_test_topic3-0 broker=0] No checkpointed highwatermark is found for partition my_test_topic3-0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,521] INFO [Partition my_test_topic3-0 broker=0] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,528] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,534] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(my_test_topic3-0 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,548] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,552] INFO Created log for partition my_test_topic3-4 in C:\logs\kafka-logs3\my_test_topic3-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,557] INFO [Partition my_test_topic3-4 broker=3] No checkpointed highwatermark is found for partition my_test_topic3-4 (kafka.cluster.Partition)
[2022-01-15 10:02:54,558] INFO [Partition my_test_topic3-4 broker=3] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,561] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic3-2, my_test_topic3-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,573] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(my_test_topic3-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,574] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(my_test_topic3-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,581] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 10:02:54,584] INFO Created log for partition my_test_topic3-1 in C:\logs\kafka-logs2\my_test_topic3-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-01-15 10:02:54,589] INFO [Partition my_test_topic3-1 broker=2] No checkpointed highwatermark is found for partition my_test_topic3-1 (kafka.cluster.Partition)
[2022-01-15 10:02:54,593] INFO [Partition my_test_topic3-1 broker=2] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 10:02:54,600] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic3-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,602] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions Map(my_test_topic3-1 -> InitialFetchState(BrokerEndPoint(id=3, host=DESKTOP-1UO7TTD:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 10:02:54,638] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 10:02:54,639] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 10:02:54,640] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 10:02:54,640] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 10:02:54,939] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic3-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 10:02:54,941] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 10:02:54,954] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic3-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 10:02:54,955] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 10:02:54,970] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition my_test_topic3-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 10:02:54,973] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:06:57,500] WARN Exception causing close of session 0x1003c0dbdef0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:06:57,517] WARN Exception causing close of session 0x1003c0dbdef0004: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:06:57,506] WARN Exception causing close of session 0x1003c0dbdef0002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:06:57,551] WARN Exception causing close of session 0x1003c0dbdef0005: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:07:12,793] INFO Expiring session 0x1003c0dbdef0005, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:07:12,794] INFO Expiring session 0x1003c0dbdef0002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:07:12,800] INFO Expiring session 0x1003c0dbdef0004, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:07:12,803] INFO Expiring session 0x1003c0dbdef0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,602] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,604] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,618] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,618] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,622] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:14:37,622] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:14:37,623] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:14:37,623] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-01-15 11:14:37,629] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-01-15 11:14:37,650] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,650] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,651] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,652] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:14:37,652] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-01-15 11:14:37,656] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:14:37,674] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,674] INFO Server environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,674] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,675] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,675] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,675] INFO Server environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,678] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,680] INFO Server environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,681] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,684] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,685] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,686] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,694] INFO Server environment:user.name=Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,696] INFO Server environment:user.home=C:\Users\Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,696] INFO Server environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,700] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,702] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,708] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,719] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,721] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,725] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 snapdir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:14:37,803] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-01-15 11:14:37,816] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:14:37,832] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:14:37,897] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-01-15 11:14:37,920] INFO Reading snapshot C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.1be (org.apache.zookeeper.server.persistence.FileSnap)
[2022-01-15 11:14:38,028] INFO Snapshotting: 0x2ba to C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.2ba (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:14:38,076] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-01-15 11:14:38,094] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2022-01-15 11:14:42,527] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:14:43,521] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:14:43,678] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:14:43,680] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:14:43,723] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:43,733] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,733] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,733] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,734] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,734] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,734] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,737] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,738] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,739] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,740] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,749] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,750] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,753] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,754] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,754] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,756] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,759] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,761] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,767] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:43,803] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:14:43,834] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:43,843] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:43,888] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:43,913] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52213, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:43,933] INFO Creating new log file: log.2bb (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-01-15 11:14:43,974] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c69e29d0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:43,987] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:44,257] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:14:44,384] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:14:44,609] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:14:44,627] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:14:44,885] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:44,923] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:45,025] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:45,028] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:45,028] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:45,034] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:45,143] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,151] INFO Attempting recovery for all logs in C:\logs\kafka-logs-admin since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:14:45,324] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,328] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,413] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,438] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\kafkabasics_topic-0, topic=kafkabasics_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 230ms (1/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,446] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,450] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,459] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,470] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (2/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,478] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,481] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,490] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,499] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (3/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,511] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,513] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,536] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,541] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (4/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,553] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,555] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,565] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,573] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (5/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,584] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,591] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,610] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,620] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic2-2, topic=my_test_topic2, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (6/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,629] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,631] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,640] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,645] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (7/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,656] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,659] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,672] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,682] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (8/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,692] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,694] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,712] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,721] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (9/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,729] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:14:45,734] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,737] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,752] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,772] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (10/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,785] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,788] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,804] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,815] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (11/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,828] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,832] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,863] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,870] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (12/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,884] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,887] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,902] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,910] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (13/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,924] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,927] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,943] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,952] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (14/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,960] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,962] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,977] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:45,986] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (15/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:45,995] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:45,999] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,017] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,025] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (16/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,039] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,042] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,056] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,059] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:14:46,061] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:14:46,065] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (17/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,075] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,078] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,092] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,100] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (18/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,116] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,120] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,141] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,141] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:46,146] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 45ms (19/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,161] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,164] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,165] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,167] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,167] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,168] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,168] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,168] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,179] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,177] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,188] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (20/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,193] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,195] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,200] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,207] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,204] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,209] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,209] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,216] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,218] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,225] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,226] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,230] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,231] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,232] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,243] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (21/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,247] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:46,262] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,266] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,295] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,304] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (22/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,318] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:14:46,319] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,321] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,338] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,342] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:46,343] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (23/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,355] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:46,361] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,369] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,387] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,389] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:46,393] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (24/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,401] INFO Socket connection established, initiating session, client: /127.0.0.1:52219, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:46,409] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,410] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,424] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c69e29d0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:46,426] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,435] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:46,432] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (25/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,452] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,455] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,469] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,491] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 52ms (26/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,502] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,506] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,524] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,533] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (27/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,551] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,554] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,569] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,574] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (28/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,587] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,590] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,604] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,612] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (29/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,628] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,632] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,651] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,657] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (30/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,670] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,675] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,691] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,698] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (31/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,706] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,707] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,719] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:14:46,721] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,731] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (32/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,740] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,742] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,759] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,766] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (33/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,777] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,780] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,796] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,805] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (34/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,818] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,822] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,842] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,848] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (35/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,857] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,865] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,879] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,886] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (36/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,895] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,899] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,912] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,919] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (37/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,931] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,934] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,951] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:14:46,957] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,964] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (38/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:46,972] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:46,974] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,988] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:46,993] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (39/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,001] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,004] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,019] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,023] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (40/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,029] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,031] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,044] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,050] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (41/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,058] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,062] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,074] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,080] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (42/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,089] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,091] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,107] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,113] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (43/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,120] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,122] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,136] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,142] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (44/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,154] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,156] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,172] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,177] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (45/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,188] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,190] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,203] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,206] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (46/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,217] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,220] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,234] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,238] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (47/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,247] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,257] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,271] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,275] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (48/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,286] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:14:47,291] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,294] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,305] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:14:47,310] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,318] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (49/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,328] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,336] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,348] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,352] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (50/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,361] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,363] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,378] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,383] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (51/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,393] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,394] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,408] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,411] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (52/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,421] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,423] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,435] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,439] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (53/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,449] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,453] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,467] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,472] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (54/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,480] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,483] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,492] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,498] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (55/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,508] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,510] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,521] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,526] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (56/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,537] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,539] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,552] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,556] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (57/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,571] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:47,572] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,586] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:47,590] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (58/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:14:47,596] INFO Loaded 58 logs in 2452ms. (kafka.log.LogManager)
[2022-01-15 11:14:47,600] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:14:47,603] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:14:47,611] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:47,671] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:47,775] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:47,778] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:47,784] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:47,788] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:47,907] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:14:47,916] INFO Attempting recovery for all logs in C:\logs\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:14:48,075] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:48,083] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,143] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,174] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 218ms (1/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:14:48,197] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:48,219] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,243] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,254] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (2/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:14:48,266] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:48,270] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,281] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,293] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (3/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:14:48,310] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:48,318] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,335] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,342] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic2-1, topic=my_test_topic2, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (4/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:14:48,354] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:48,356] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,386] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,395] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 52ms (5/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:14:48,410] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:48,413] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,422] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:48,432] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (6/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:14:48,439] INFO Loaded 6 logs in 532ms. (kafka.log.LogManager)
[2022-01-15 11:14:48,441] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:14:48,445] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:14:48,496] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:14:48,700] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:14:48,705] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:14:48,752] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:48,766] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,766] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,766] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,767] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,767] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,767] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,772] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,772] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,774] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,783] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,785] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,786] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,788] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,790] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,791] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,794] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,796] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,799] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,809] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:48,830] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:14:48,843] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-01-15 11:14:48,856] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:14:48,876] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:48,883] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:48,901] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:48,909] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52224, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:48,923] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c69e29d0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:48,933] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:48,966] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:49,032] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:49,083] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,087] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,087] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,087] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,123] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:14:49,127] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:14:49,256] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:49,317] INFO Stat of the created znode at /brokers/ids/0 is: 744,744,1642266889301,1642266889301,1,0,0,72124019509100544,214,0,744
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:49,321] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9092, czxid (broker epoch): 744 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:49,490] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,500] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,500] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,541] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:49,564] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:14:49,613] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:14:49,620] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:49,707] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:8000,blockEndProducerId:8999) by writing to Zk with path version 9 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:14:49,720] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:49,732] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:14:49,737] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:49,756] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:14:49,834] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:14:49,856] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-01-15 11:14:49,859] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:49,931] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:14:49,953] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:49,998] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:50,020] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:50,058] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:50,063] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:50,067] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:50,119] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:50,175] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:50,192] INFO Kafka startTimeMs: 1642266890072 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:50,197] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-01-15 11:14:50,211] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:50,210] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:50,234] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:50,210] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:50,238] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:50,210] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:50,281] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:50,300] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:50,309] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:50,309] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:50,350] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, kafkabasics_topic-0, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, my_test_topic-3, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, my_test_topic3-3, __consumer_offsets-18, __consumer_offsets-37, my_test_topic2-2, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:50,394] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,397] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:14:50,418] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:50,422] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,428] INFO Attempting recovery for all logs in C:\logs\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:14:50,434] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,476] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,485] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,491] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,501] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,516] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,566] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,574] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,582] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:50,584] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,593] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,601] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,607] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,618] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,626] INFO [Partition kafkabasics_topic-0 broker=0] Log loaded for partition kafkabasics_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,642] INFO Stat of the created znode at /brokers/ids/1 is: 775,775,1642266890611,1642266890611,1,0,0,72124019509100545,214,0,775
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:50,647] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9093, czxid (broker epoch): 775 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:50,657] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,665] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,675] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,686] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,698] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,704] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,724] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,732] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,742] INFO [Partition my_test_topic-3 broker=0] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,750] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,764] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:50,773] INFO [Partition my_test_topic2-2 broker=0] Log loaded for partition my_test_topic2-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,779] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:50,784] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,795] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,809] INFO [Partition my_test_topic3-3 broker=0] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,817] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,825] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,835] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,853] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,860] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,870] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,886] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,893] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,901] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,907] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,906] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:50,916] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,924] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,942] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,935] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:50,950] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,940] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 447ms (1/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:50,958] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,973] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,961] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:50,969] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:50,981] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:50,969] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:50,980] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:50,990] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,010] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,013] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,018] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,021] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,026] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 72ms (2/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:51,036] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,050] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,060] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,055] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:51,069] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,072] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,081] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,088] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,095] INFO [Partition my_test_topic3-0 broker=0] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,095] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 58ms (3/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:51,100] INFO [Partition my_test_topic-0 broker=0] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,105] INFO [Partition my_test_topic-4 broker=0] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,111] INFO [Partition my_test_topic-1 broker=0] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:51,126] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:51,130] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,152] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,153] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,160] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,168] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (4/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:51,167] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,186] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:51,182] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,192] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,188] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 27 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,193] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,214] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,223] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,217] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 12 milliseconds, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,234] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,237] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,240] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,242] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic2-3, topic=my_test_topic2, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 72ms (5/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:51,242] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,251] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:14:51,249] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,256] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:51,258] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:51,259] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,272] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:51,268] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,236] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 25 milliseconds, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,279] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:14:51,273] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,301] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,290] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,278] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 61 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,309] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 63ms (6/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:51,307] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,314] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,321] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,327] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,332] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:51,330] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,339] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,311] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 74 milliseconds, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,338] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,355] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 114 milliseconds, of which 113 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,356] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 101 milliseconds, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,361] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,366] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,364] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 91 milliseconds, of which 90 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,375] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 60ms (7/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:51,365] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,369] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 62 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,384] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,406] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 84 milliseconds, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,406] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,411] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,405] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:51,414] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,420] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,425] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,411] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 82 milliseconds, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,427] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,434] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,439] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,441] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:51,442] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,446] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,456] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:51,449] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,471] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,470] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 94ms (8/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:14:51,473] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,482] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,483] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,484] INFO Loaded 8 logs in 1065ms. (kafka.log.LogManager)
[2022-01-15 11:14:51,485] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,487] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,489] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,490] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:14:51,490] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,493] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,494] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,496] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:14:51,433] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 76 milliseconds, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,496] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,503] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,504] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,506] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,508] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,509] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,510] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,520] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:14:51,516] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,535] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,537] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,541] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,542] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,544] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,547] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,556] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,561] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,575] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,577] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,501] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 136 milliseconds, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,579] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,584] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,586] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,584] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 178 milliseconds, of which 176 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,591] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 180 milliseconds, of which 179 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,606] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:51,599] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,608] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,619] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,622] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 178 milliseconds, of which 177 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,626] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,630] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 196 milliseconds, of which 193 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,635] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:51,636] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:51,630] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,640] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,642] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,644] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,653] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,654] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,655] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:51,660] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,665] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:51,668] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,678] INFO Kafka startTimeMs: 1642266891637 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:51,680] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,687] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,690] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,689] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-01-15 11:14:51,632] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 193 milliseconds, of which 192 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,692] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,699] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 253 milliseconds, of which 252 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,706] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,715] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,718] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,714] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 244 milliseconds, of which 244 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,720] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 241 milliseconds, of which 240 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,728] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 249 milliseconds, of which 247 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,734] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:51,737] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 248 milliseconds, of which 248 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,737] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 248 milliseconds, of which 247 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,750] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 255 milliseconds, of which 255 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,753] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 249 milliseconds, of which 248 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,774] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 267 milliseconds, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,790] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 280 milliseconds, of which 280 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 275 milliseconds, of which 275 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 258 milliseconds, of which 258 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 257 milliseconds, of which 257 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 258 milliseconds, of which 257 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,805] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 249 milliseconds, of which 249 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,808] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 247 milliseconds, of which 246 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,811] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 234 milliseconds, of which 234 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,813] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 229 milliseconds, of which 229 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,819] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 228 milliseconds, of which 228 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,824] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 217 milliseconds, of which 216 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,827] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 207 milliseconds, of which 207 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,829] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 203 milliseconds, of which 203 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 199 milliseconds, of which 199 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,848] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 203 milliseconds, of which 202 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,850] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 196 milliseconds, of which 196 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,857] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 189 milliseconds, of which 188 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 175 milliseconds, of which 175 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,865] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 174 milliseconds, of which 174 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,861] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-3, my_test_topic-3) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:51,876] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 161 milliseconds, of which 160 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,891] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 171 milliseconds, of which 171 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,893] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 159 milliseconds, of which 159 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,903] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 158 milliseconds, of which 150 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:14:51,920] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-0, my_test_topic-0, my_test_topic-4, my_test_topic-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:51,993] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:52,035] INFO [Partition my_test_topic-2 broker=1] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:52,037] INFO [Partition my_test_topic2-1 broker=1] Log loaded for partition my_test_topic2-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:52,039] INFO [Partition my_test_topic3-2 broker=1] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:52,085] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:14:52,092] INFO [Partition my_test_topic3-3 broker=1] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:52,097] INFO [Partition my_test_topic-3 broker=1] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:52,100] INFO [Partition my_test_topic-0 broker=1] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:52,105] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic3-3, my_test_topic-3, my_test_topic-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:52,169] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:52,182] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),3,0), my_test_topic3-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),1,0), my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),2,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:52,184] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic3-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:52,187] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:52,193] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:52,194] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:52,197] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:52,201] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:52,268] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic2-1, my_test_topic3-2) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:52,311] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:14:52,314] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:14:52,362] INFO [Partition my_test_topic-0 broker=0] ISR updated to 0,1 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:14:52,374] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:52,391] INFO [Partition my_test_topic-3 broker=0] ISR updated to 0,1 and version updated to [3] (kafka.cluster.Partition)
[2022-01-15 11:14:52,392] INFO [Partition my_test_topic3-3 broker=0] ISR updated to 0,1 and version updated to [2] (kafka.cluster.Partition)
[2022-01-15 11:14:52,394] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,395] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,396] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,397] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,399] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,399] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,403] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,404] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,407] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,409] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,411] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,412] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,421] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,422] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,424] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,426] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,426] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,428] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,439] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:14:52,465] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:14:52,478] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:52,483] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:52,496] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:52,503] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52263, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:52,517] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c69e29d0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:14:52,523] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:14:52,706] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:14:52,818] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:14:52,827] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-01-15 11:14:52,904] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:52,955] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:52,993] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:52,996] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:52,996] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:53,000] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:53,006] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:14:53,020] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:14:53,038] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:14:53,135] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:53,167] INFO Stat of the created znode at /brokers/ids/2 is: 798,798,1642266893154,1642266893154,1,0,0,72124019509100546,214,0,798
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:53,170] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9094, czxid (broker epoch): 798 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:53,229] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:53,266] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:14:53,319] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:53,330] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:53,334] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:53,360] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:53,364] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:53,367] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:53,365] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:53,372] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:14:53,391] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:53,452] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:14:53,453] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:53,463] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:53,465] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:14:53,468] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:53,479] INFO Attempting recovery for all logs in C:\logs\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:14:53,535] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:53,572] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:14:53,620] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:53,624] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:53,634] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,636] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:53,638] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:53,658] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:53,662] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:53,669] INFO Kafka startTimeMs: 1642266893641 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:53,675] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-01-15 11:14:53,721] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,742] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 228ms (1/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:53,751] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:53,755] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,767] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,778] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (2/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:53,792] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:53,795] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,816] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,829] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (3/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:53,844] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:53,851] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:53,856] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,871] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,883] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (4/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:53,893] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:53,895] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,911] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,923] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-0, topic=my_test_topic2, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (5/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:53,939] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:53,943] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,961] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:53,969] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-4, topic=my_test_topic2, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (6/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:53,981] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:53,986] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:54,001] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:54,010] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (7/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:54,022] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:54,025] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:54,036] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:54,043] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (8/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:54,050] INFO [Partition my_test_topic-2 broker=2] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,054] INFO [Partition my_test_topic3-0 broker=2] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,055] INFO [Partition my_test_topic-0 broker=2] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,062] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:14:54,064] INFO [Partition my_test_topic2-3 broker=2] Log loaded for partition my_test_topic2-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,066] INFO [Partition my_test_topic3-4 broker=2] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,067] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:54,068] INFO [Partition my_test_topic-4 broker=2] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,071] INFO [Partition my_test_topic3-1 broker=2] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,078] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:14:54,073] INFO [Partition my_test_topic-1 broker=2] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:54,085] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-1, my_test_topic3-0, my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:54,086] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (9/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:14:54,103] INFO Loaded 9 logs in 634ms. (kafka.log.LogManager)
[2022-01-15 11:14:54,107] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:14:54,112] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:14:54,156] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:54,164] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(my_test_topic3-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),2,0), my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),3,0), my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),3,0), my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),3,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:54,167] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:54,171] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:54,176] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:54,177] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),4,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:54,178] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:54,180] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:54,178] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic3-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:54,189] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:54,190] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:54,192] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:54,194] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:54,198] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:54,248] INFO [Partition my_test_topic-4 broker=0] ISR updated to 0,2 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:14:54,269] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic2-3, my_test_topic3-4, my_test_topic3-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:54,278] INFO [Partition my_test_topic3-0 broker=0] ISR updated to 0,2 and version updated to [3] (kafka.cluster.Partition)
[2022-01-15 11:14:54,289] INFO [Partition my_test_topic-0 broker=0] ISR updated to 0,1,2 and version updated to [5] (kafka.cluster.Partition)
[2022-01-15 11:14:54,289] INFO [Partition my_test_topic-1 broker=0] ISR updated to 0,2 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:14:54,347] INFO [Partition my_test_topic-2 broker=1] ISR updated to 1,2 and version updated to [5] (kafka.cluster.Partition)
[2022-01-15 11:14:54,971] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:14:54,978] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-01-15 11:14:55,113] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:55,188] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:55,245] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,249] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,250] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,253] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,285] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:14:55,418] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:55,454] INFO Stat of the created znode at /brokers/ids/3 is: 808,808,1642266895441,1642266895441,1,0,0,72124019509100547,214,0,808
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:55,456] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9095, czxid (broker epoch): 808 (kafka.zk.KafkaZkClient)
[2022-01-15 11:14:55,588] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,608] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,613] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,665] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:55,693] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:55,708] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:14:55,717] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),4,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:55,726] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:55,727] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:55,729] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic3-0, my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:55,729] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:55,781] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-0, my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:55,829] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:14:55,831] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:55,838] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:55,842] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:14:55,843] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),4,0), my_test_topic3-0 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),3,0), my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),4,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:55,859] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:14:55,924] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:14:55,970] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:14:56,013] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:56,023] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:14:56,024] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:14:56,036] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:56,036] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:56,042] INFO Kafka startTimeMs: 1642266896024 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:14:56,051] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-01-15 11:14:56,193] INFO [broker-3-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:14:56,287] INFO [Partition my_test_topic-2 broker=3] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,292] INFO [Partition my_test_topic2-4 broker=3] Log loaded for partition my_test_topic2-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,292] INFO [Partition my_test_topic3-2 broker=3] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,295] INFO [Partition my_test_topic-3 broker=3] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,298] INFO [Partition my_test_topic3-4 broker=3] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,299] INFO [Partition my_test_topic-4 broker=3] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,300] INFO [Partition my_test_topic2-0 broker=3] Log loaded for partition my_test_topic2-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,302] INFO [Partition my_test_topic3-1 broker=3] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,307] INFO [Partition my_test_topic-1 broker=3] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:14:56,312] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-1, my_test_topic3-2, my_test_topic-3, my_test_topic3-4, my_test_topic3-1, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:56,366] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,372] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(my_test_topic3-1 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),3,0), my_test_topic3-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),3,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:56,374] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,378] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:56,385] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,386] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:56,386] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),2,0), my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),3,0), my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),3,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:56,392] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,395] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,398] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:56,404] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,404] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:56,407] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(my_test_topic3-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),3,0), my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),4,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:56,409] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,413] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,409] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,421] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:56,422] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:56,426] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic3-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,427] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:56,477] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Partition my_test_topic-4 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,471] INFO [Partition my_test_topic-2 broker=1] ISR updated to 1,2,3 and version updated to [6] (kafka.cluster.Partition)
[2022-01-15 11:14:56,491] WARN [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Partition my_test_topic-4 marked as failed (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:56,510] INFO [Partition my_test_topic-1 broker=0] ISR updated to 0,2,3 and version updated to [5] (kafka.cluster.Partition)
[2022-01-15 11:14:56,537] INFO [Partition my_test_topic3-2 broker=1] ISR updated to 1,3 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:14:56,542] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic2-4, my_test_topic2-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:56,568] INFO [Partition my_test_topic3-1 broker=2] ISR updated to 2,3 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:14:56,588] INFO [Partition my_test_topic-3 broker=0] ISR updated to 0,1,3 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:14:56,599] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:56,607] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),4,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:14:56,604] INFO [Partition my_test_topic3-4 broker=2] ISR updated to 2,3 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:14:57,003] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:14:57,004] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:14:57,041] INFO [Partition my_test_topic-4 broker=2] ISR updated to 0,2,3 and version updated to [6] (kafka.cluster.Partition)
[2022-01-15 11:17:06,105] WARN Exception causing close of session 0x1003c69e29d0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:17:06,108] WARN Exception causing close of session 0x1003c69e29d0001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:17:06,125] WARN Exception causing close of session 0x1003c69e29d0002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:17:06,134] WARN Exception causing close of session 0x1003c69e29d0003: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:24:24,944] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,947] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,960] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,960] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,963] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:24:24,964] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:24:24,965] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:24:24,966] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-01-15 11:24:24,971] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-01-15 11:24:24,991] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,991] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,992] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,993] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:24:24,993] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-01-15 11:24:24,997] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:24:25,013] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,013] INFO Server environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,013] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,014] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,014] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,014] INFO Server environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,017] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,018] INFO Server environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,019] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,020] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,022] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,024] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,026] INFO Server environment:user.name=Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,033] INFO Server environment:user.home=C:\Users\Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,034] INFO Server environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,036] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,037] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,038] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,043] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,044] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,046] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 snapdir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:25,110] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-01-15 11:24:25,116] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:24:25,126] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:24:25,164] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-01-15 11:24:25,172] INFO Reading snapshot C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.2ba (org.apache.zookeeper.server.persistence.FileSnap)
[2022-01-15 11:24:25,303] INFO Snapshotting: 0x335 to C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.335 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:24:25,375] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-01-15 11:24:25,385] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2022-01-15 11:24:29,394] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:24:30,327] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:24:30,475] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:24:30,477] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:24:30,508] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:30,515] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,516] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,516] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,516] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,516] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,517] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,520] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,521] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,522] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,523] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,526] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,533] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,533] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,535] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,536] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,537] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,538] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,543] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,550] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:30,586] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:24:30,605] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:30,611] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:30,627] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:30,635] INFO Socket connection established, initiating session, client: /127.0.0.1:64151, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:30,654] INFO Creating new log file: log.336 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-01-15 11:24:30,691] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c72d8c10000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:30,708] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:30,985] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:31,302] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:24:31,314] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:24:31,386] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:24:31,464] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:24:31,492] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:24:31,563] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:31,567] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:31,569] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:31,574] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:31,654] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:31,665] INFO Attempting recovery for all logs in C:\logs\kafka-logs-admin since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:24:31,836] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:31,843] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:31,906] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:31,923] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\kafkabasics_topic-0, topic=kafkabasics_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 177ms (1/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:31,933] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:31,935] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:31,948] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:31,959] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (2/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:31,965] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:31,967] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:31,980] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:31,986] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (3/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:31,996] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:31,998] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,010] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,016] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (4/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,025] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,028] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,039] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,045] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (5/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,066] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,068] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,080] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,085] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic2-2, topic=my_test_topic2, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (6/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,093] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,095] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,105] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,113] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (7/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,122] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,126] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,138] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,145] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (8/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,152] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,154] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,165] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,175] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (9/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,182] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,184] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,197] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,205] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (10/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,213] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,215] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,227] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,234] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (11/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,242] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,246] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,256] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,262] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (12/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,269] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,271] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,281] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,287] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (13/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,296] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,297] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,309] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,315] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (14/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,326] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,328] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,347] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,355] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (15/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,367] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,369] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,383] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,388] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (16/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,399] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,400] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,415] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,423] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (17/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,430] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,435] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,449] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,453] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (18/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,462] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,463] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,477] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,480] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (19/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,491] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,494] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,515] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,529] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (20/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,546] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,548] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,553] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:24:32,563] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,570] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (21/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,580] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,582] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,598] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,601] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (22/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,610] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,612] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,621] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,626] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (23/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,633] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,635] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,655] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,663] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (24/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,671] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,675] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,694] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,704] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (25/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,725] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,727] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,741] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,745] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (26/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,752] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,754] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,765] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,769] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (27/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,776] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,778] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,788] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,791] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (28/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,799] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,800] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,801] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:24:32,802] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:24:32,811] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,817] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (29/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,830] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,832] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,849] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,856] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (30/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,865] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,868] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:32,868] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,885] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,885] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,886] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,884] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,886] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,886] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,894] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (31/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,887] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,897] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,911] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,914] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,898] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,920] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,925] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,928] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,944] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,930] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,945] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,950] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (32/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:32,948] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,953] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,959] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,963] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:32,966] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,963] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,974] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,986] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:32,988] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:32,992] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (33/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,005] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,010] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,024] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,031] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (34/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,037] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:24:33,043] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,047] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,059] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:33,066] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,066] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:33,075] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (35/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,100] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,103] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,110] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:33,120] INFO Socket connection established, initiating session, client: /127.0.0.1:64855, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:33,128] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,133] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 49ms (36/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,142] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c72d8c10001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:33,146] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,150] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,158] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:33,167] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,180] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (37/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,202] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,211] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,243] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,249] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 63ms (38/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,270] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,281] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,308] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,313] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 62ms (39/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,326] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,328] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,347] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,353] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (40/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,363] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,366] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,383] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,389] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (41/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,402] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,404] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,420] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,427] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (42/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,443] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,446] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,464] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,473] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (43/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,491] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,496] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,516] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,521] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (44/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,531] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:33,537] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,542] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,565] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,570] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 48ms (45/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,581] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,584] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,599] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,601] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (46/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,611] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,615] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,625] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,630] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (47/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,637] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,639] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,655] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,660] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (48/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,669] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,672] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,692] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,699] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (49/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,714] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,718] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,733] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,738] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (50/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,750] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,753] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,769] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,773] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (51/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,790] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,797] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,815] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,818] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (52/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,831] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,832] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,845] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,849] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (53/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,861] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,864] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,884] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,890] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (54/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,901] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,903] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,921] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,926] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (55/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,935] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,937] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,949] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,952] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (56/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:33,963] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:33,966] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,985] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:33,993] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (57/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:34,014] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:34,017] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,037] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,046] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (58/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:24:34,056] INFO Loaded 58 logs in 2401ms. (kafka.log.LogManager)
[2022-01-15 11:24:34,059] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:24:34,064] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:24:34,158] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:24:34,171] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:24:34,370] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:24:34,399] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:24:34,495] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:34,499] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:34,499] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:34,507] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:34,635] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:24:34,643] INFO Attempting recovery for all logs in C:\logs\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:24:34,777] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:34,783] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,856] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,882] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 208ms (1/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:24:34,898] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:34,900] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,922] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,931] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 48ms (2/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:24:34,941] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:34,944] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,953] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:34,963] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (3/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:24:34,981] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:34,984] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:35,008] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:35,008] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:24:35,027] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic2-1, topic=my_test_topic2, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 61ms (4/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:24:35,033] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-01-15 11:24:35,059] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:35,066] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:35,093] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:35,102] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 60ms (5/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:24:35,112] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:24:35,114] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:35,121] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:24:35,130] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (6/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:24:35,134] INFO Loaded 6 logs in 499ms. (kafka.log.LogManager)
[2022-01-15 11:24:35,135] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:24:35,139] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:24:35,176] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:24:35,239] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:35,276] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,281] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,281] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,281] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,309] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:35,419] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:24:35,466] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72124019509100544' does not match current session '72124057998393344' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-01-15 11:24:35,479] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-01-15 11:24:35,483] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:24:35,485] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:24:35,493] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:24:35,502] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-01-15 11:24:35,504] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:35,506] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:35,506] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:35,507] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:24:35,514] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:24:35,515] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:24:35,517] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:24:35,519] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,698] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,698] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,701] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,888] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,888] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,893] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,906] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,907] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:35,912] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,107] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,107] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,123] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-01-15 11:24:36,126] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:36,129] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:36,129] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:36,143] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-01-15 11:24:36,150] INFO Shutting down. (kafka.log.LogManager)
[2022-01-15 11:24:36,295] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:24:36,310] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-01-15 11:24:36,383] INFO Shutdown complete. (kafka.log.LogManager)
[2022-01-15 11:24:36,385] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:36,387] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:36,387] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:36,394] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:36,399] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:24:36,465] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:36,517] INFO Session: 0x1003c72d8c10000 closed (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:36,518] INFO EventThread shut down for session: 0x1003c72d8c10000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:36,521] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:36,530] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:36,561] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,574] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,574] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,579] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,592] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:36,592] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:36,593] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:36,609] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:36,609] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:36,611] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:36,630] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:36,776] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:24:36,815] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '72124019509100545' does not match current session '72124057998393345' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-01-15 11:24:36,833] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-01-15 11:24:36,841] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:24:36,851] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:24:36,868] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:24:36,883] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-01-15 11:24:36,885] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:36,888] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:36,888] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:24:36,890] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:24:36,900] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:24:36,902] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:24:36,904] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:24:36,909] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,998] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,998] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:36,999] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,169] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,169] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,177] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,184] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,184] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,195] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,200] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,200] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:24:37,226] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-01-15 11:24:37,227] INFO [broker-1-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:37,229] INFO [broker-1-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:37,229] INFO [broker-1-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:24:37,243] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-01-15 11:24:37,246] INFO Shutting down. (kafka.log.LogManager)
[2022-01-15 11:24:37,342] INFO Shutdown complete. (kafka.log.LogManager)
[2022-01-15 11:24:37,344] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:37,347] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:37,347] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:24:37,354] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:37,467] INFO Session: 0x1003c72d8c10001 closed (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:24:37,467] INFO EventThread shut down for session: 0x1003c72d8c10001 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:24:37,470] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:24:37,476] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:37,526] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:37,526] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:37,530] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:37,618] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:37,618] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:37,626] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:38,532] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:38,532] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:38,544] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:38,624] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:38,624] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:38,638] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-01-15 11:24:38,764] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-01-15 11:24:38,765] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:24:38,768] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:24:38,771] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:24:38,781] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-01-15 11:24:38,795] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:24:38,796] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-01-15 11:24:38,797] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-01-15 11:24:38,805] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:24:39,535] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:39,535] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:39,536] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:40,538] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:40,538] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:24:40,551] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-01-15 11:24:40,710] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-01-15 11:24:40,712] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:24:40,714] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:24:40,718] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:24:40,726] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-01-15 11:24:40,735] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:24:40,738] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-01-15 11:24:40,741] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-01-15 11:24:40,744] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:24:45,794] INFO Expiring session 0x1003c69e29d0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:45,795] INFO Expiring session 0x1003c69e29d0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:45,795] INFO Expiring session 0x1003c69e29d0003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:24:45,796] INFO Expiring session 0x1003c69e29d0002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:28:23,988] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:28:24,998] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:28:25,143] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:28:25,144] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:28:25,178] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:28:25,186] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,186] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,186] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,186] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,187] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,188] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,189] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,190] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,192] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,194] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,195] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,196] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,198] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,214] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,214] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,215] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,215] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,216] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,221] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:28:25,259] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:28:25,272] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:28:25,275] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:28:25,288] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:28:27,346] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:14,247] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,250] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,263] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,263] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,267] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:40:14,268] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:40:14,268] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:40:14,269] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-01-15 11:40:14,276] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-01-15 11:40:14,297] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,298] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,299] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,299] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:40:14,300] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-01-15 11:40:14,305] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:40:14,321] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,321] INFO Server environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,322] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,322] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,322] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,323] INFO Server environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,328] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,330] INFO Server environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,331] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,332] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,345] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,347] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,350] INFO Server environment:user.name=Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,355] INFO Server environment:user.home=C:\Users\Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,362] INFO Server environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,365] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,369] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,377] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,390] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,391] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,396] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 snapdir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:40:14,464] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-01-15 11:40:14,474] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:40:14,489] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:40:14,543] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-01-15 11:40:14,550] INFO Reading snapshot C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.335 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-01-15 11:40:14,612] INFO Snapshotting: 0x35b to C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.35b (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:40:14,648] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-01-15 11:40:14,662] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2022-01-15 11:40:17,490] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:40:18,380] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:40:18,509] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:40:18,510] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:40:18,541] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:18,549] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,549] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,550] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,550] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,550] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,551] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,556] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,562] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,563] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,565] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,566] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,569] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,572] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,579] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,582] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,585] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,588] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,593] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,607] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:18,674] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:40:18,711] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:18,724] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:18,752] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:18,764] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:60229, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:18,780] INFO Creating new log file: log.35c (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-01-15 11:40:18,806] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c8154e00000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:18,813] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:18,999] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:40:19,314] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:40:19,328] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:40:19,520] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:19,558] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:19,661] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:19,665] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:19,668] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:19,672] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:19,774] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:19,783] INFO Skipping recovery for all logs in C:\logs\kafka-logs-admin since clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:40:19,867] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:40:20,004] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,030] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\kafkabasics_topic-0, topic=kafkabasics_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 175ms (1/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,042] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,049] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (2/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,062] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,072] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (3/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,086] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,096] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (4/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,110] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,121] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (5/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,132] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,142] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic2-2, topic=my_test_topic2, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (6/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,167] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,175] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (7/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,193] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,198] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (8/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,212] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,220] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (9/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,231] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,239] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (10/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,249] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,258] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (11/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,276] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,282] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (12/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,298] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,309] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (13/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,327] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,334] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (14/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,356] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,365] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (15/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,381] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,392] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (16/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,406] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,413] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (17/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,428] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,436] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (18/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,448] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,455] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (19/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,466] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,474] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (20/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,489] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,497] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (21/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,511] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,519] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (22/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,528] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,538] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (23/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,548] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,553] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (24/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,564] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,567] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (25/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,579] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,583] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (26/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,595] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,603] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (27/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,617] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,624] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (28/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,638] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,642] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (29/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,655] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,659] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (30/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,673] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,677] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (31/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,690] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,694] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (32/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,708] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,712] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (33/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,727] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,733] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (34/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,748] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,757] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (35/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,773] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,779] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (36/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,793] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,799] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (37/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,826] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,839] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (38/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,861] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,871] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (39/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,902] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,908] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (40/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,931] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,942] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (41/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,966] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,973] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (42/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:20,990] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:20,997] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (43/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,014] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,020] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (44/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,031] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,037] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (45/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,054] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,060] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (46/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,072] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,075] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (47/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,092] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,097] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (48/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,113] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,118] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (49/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,130] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,136] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (50/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,148] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,153] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (51/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,162] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,166] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (52/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,177] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,180] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (53/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,194] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,199] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (54/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,210] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,216] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (55/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,227] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,231] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (56/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,245] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,251] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (57/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,266] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:21,274] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (58/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:40:21,281] INFO Loaded 58 logs in 1506ms. (kafka.log.LogManager)
[2022-01-15 11:40:21,283] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:40:21,285] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:40:21,309] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:40:21,487] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:40:21,489] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:40:21,548] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:21,559] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,560] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,561] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,562] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,565] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,566] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,573] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,574] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,575] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,576] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,578] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,587] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,588] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,589] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,591] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,592] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,593] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,595] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,607] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:21,638] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:40:21,651] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:21,657] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:21,669] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:21,678] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:60233, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:21,706] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c8154e00001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:21,714] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:21,896] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:40:22,270] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:40:22,297] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:40:22,349] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:40:22,364] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-01-15 11:40:22,459] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:22,582] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:22,589] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:22,660] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:22,665] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:22,678] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:22,678] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:22,683] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:22,729] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:40:22,839] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:22,847] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:22,839] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:22,848] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:22,886] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:22,908] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:40:22,947] INFO Stat of the created znode at /brokers/ids/0 is: 890,890,1642268422924,1642268422924,1,0,0,72124120210341888,214,0,890
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:22,949] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9092, czxid (broker epoch): 890 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:22,990] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:40:22,997] INFO Skipping recovery for all logs in C:\logs\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:40:23,116] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:23,133] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:23,145] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:23,186] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:23,278] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:23,354] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:23,386] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 342ms (1/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:40:23,400] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:23,456] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (2/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:40:23,498] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:23,514] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:12000,blockEndProducerId:12999) by writing to Zk with path version 13 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:40:23,525] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 63ms (3/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:40:23,549] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:23,576] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:23,606] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:23,616] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:40:23,629] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic2-1, topic=my_test_topic2, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (4/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:40:23,665] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:23,680] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (5/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:40:23,710] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:23,739] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:23,741] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 49ms (6/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:40:23,750] INFO Loaded 6 logs in 759ms. (kafka.log.LogManager)
[2022-01-15 11:40:23,758] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:40:23,764] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:40:23,821] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:40:23,902] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:23,916] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:23,918] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:23,947] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:23,948] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:23,957] INFO Kafka startTimeMs: 1642268423921 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:23,964] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-01-15 11:40:24,017] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:24,177] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, kafkabasics_topic-0, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, my_test_topic-3, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, my_test_topic3-3, __consumer_offsets-18, __consumer_offsets-37, my_test_topic2-2, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, my_test_topic-1, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:24,206] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,235] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,245] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,259] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,272] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,280] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,294] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,309] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,320] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,329] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,338] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,346] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,362] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,370] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,377] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,386] INFO [Partition kafkabasics_topic-0 broker=0] Log loaded for partition kafkabasics_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,397] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,409] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,417] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,426] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,433] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,441] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,449] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,459] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,471] INFO [Partition my_test_topic-3 broker=0] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,479] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,488] INFO [Partition my_test_topic2-2 broker=0] Log loaded for partition my_test_topic2-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,495] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,502] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,508] INFO [Partition my_test_topic3-3 broker=0] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,514] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,520] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,525] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,531] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,538] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,544] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,551] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,560] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,568] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,575] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,582] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,589] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,595] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,602] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,609] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,616] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,623] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,629] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,636] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,645] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,654] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,662] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,675] INFO [Partition my_test_topic-1 broker=0] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,683] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:40:24,686] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,696] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,713] INFO [Partition my_test_topic3-0 broker=0] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,722] INFO [Partition my_test_topic-0 broker=0] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,723] INFO [Partition my_test_topic-4 broker=0] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:24,749] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,753] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,760] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,762] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,768] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,774] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,775] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 21 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,777] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,781] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 21 milliseconds, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,781] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,785] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 17 milliseconds, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,787] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,788] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 15 milliseconds, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,789] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 15 milliseconds, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,792] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,799] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,807] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 12 milliseconds, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,807] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,809] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 18 milliseconds, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,814] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,820] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 13 milliseconds, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,822] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,820] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,829] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,830] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,837] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,838] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,839] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,848] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,849] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,850] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,853] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,856] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,863] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,865] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,870] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,874] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,870] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,876] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,879] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,880] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,884] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,885] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,888] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,894] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,895] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 2 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,896] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,899] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,900] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,902] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,911] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,911] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,912] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,916] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,917] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,924] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,928] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,928] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,929] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,937] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,937] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,938] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,941] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,941] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,942] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,945] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,945] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,946] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,957] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,958] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,959] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,963] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,964] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,965] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,969] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:40:24,970] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,972] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:40:24,970] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,973] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,977] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,977] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,978] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,989] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,990] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,994] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,994] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,995] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:24,998] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:24,999] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,000] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,003] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,005] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,008] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,009] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,022] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,022] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,023] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,027] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,027] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,028] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,032] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,032] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,033] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,037] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,037] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:25,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,038] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,048] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,049] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,052] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,050] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,054] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,055] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,057] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,055] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,062] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,058] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,066] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,069] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,071] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,070] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,080] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,072] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,084] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,086] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,088] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,087] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,097] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,096] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,101] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,101] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,103] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,101] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,106] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,109] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,111] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,111] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,112] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,117] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,113] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,119] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,129] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,130] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,129] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,133] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,140] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,140] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,141] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,144] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1f6c9cd8 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:25,146] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,146] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,160] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,160] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,161] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,164] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:25,165] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,166] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,171] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 11:40:25,190] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:40:25,210] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:25,210] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-3, my_test_topic-3, my_test_topic-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:25,216] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:25,237] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:25,247] INFO Socket connection established, initiating session, client: /127.0.0.1:60253, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:25,262] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-0, my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:25,281] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c8154e00002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:25,294] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:25,378] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:40:25,390] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-01-15 11:40:25,469] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:25,470] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:40:25,544] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:25,589] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:25,593] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:25,594] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:25,593] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:25,625] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:40:25,748] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:25,803] INFO Stat of the created znode at /brokers/ids/1 is: 935,935,1642268425785,1642268425785,1,0,0,72124120210341889,214,0,935
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:25,806] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9093, czxid (broker epoch): 935 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:25,874] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:40:25,890] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:40:25,919] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:40:25,978] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:25,994] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:25,994] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:26,034] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:26,060] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:26,121] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:13000,blockEndProducerId:13999) by writing to Zk with path version 14 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:40:26,131] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:26,110] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:26,141] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:26,146] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:40:26,159] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:26,220] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:26,260] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:40:26,264] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:26,264] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:26,271] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:26,273] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:26,310] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:26,323] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:26,324] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:26,338] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:26,339] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:26,340] INFO Kafka startTimeMs: 1642268426325 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:26,345] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-01-15 11:40:26,399] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:26,415] INFO Attempting recovery for all logs in C:\logs\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:40:26,551] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:26,588] INFO [Partition my_test_topic-2 broker=1] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:26,599] INFO [Partition my_test_topic2-1 broker=1] Log loaded for partition my_test_topic2-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:26,603] INFO [Partition my_test_topic3-2 broker=1] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:26,615] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:26,623] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,674] INFO [Partition my_test_topic3-3 broker=1] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:26,678] INFO [Partition my_test_topic-3 broker=1] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:26,681] INFO [Partition my_test_topic-0 broker=1] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:26,686] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,690] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic3-3, my_test_topic-3, my_test_topic-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:26,724] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 257ms (1/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:26,740] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:26,743] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,751] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,760] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (2/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:26,772] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:26,775] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,782] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:26,788] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,795] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(my_test_topic3-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),2,0), my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),4,0), my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),7,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:26,797] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic3-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:26,803] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (3/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:26,804] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:26,809] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:26,813] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:26,814] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:26,818] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:26,829] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:26,831] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,846] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,856] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 52ms (4/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:26,869] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:26,871] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,875] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic2-1, my_test_topic3-2) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:26,888] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,902] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic2-3, topic=my_test_topic2, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (5/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:26,919] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:26,924] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,962] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:26,981] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (6/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:26,998] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:27,007] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:27,031] INFO [Partition my_test_topic-0 broker=0] ISR updated to 0,1 and version updated to [10] (kafka.cluster.Partition)
[2022-01-15 11:40:27,042] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:27,055] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (7/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:27,071] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:27,073] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:27,091] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:27,101] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 45ms (8/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:40:27,105] INFO [Partition my_test_topic-3 broker=0] ISR updated to 0,1 and version updated to [7] (kafka.cluster.Partition)
[2022-01-15 11:40:27,106] INFO [Partition my_test_topic3-3 broker=0] ISR updated to 0,1 and version updated to [4] (kafka.cluster.Partition)
[2022-01-15 11:40:27,139] INFO Loaded 8 logs in 735ms. (kafka.log.LogManager)
[2022-01-15 11:40:27,141] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:40:27,146] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:40:27,379] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:40:27,536] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:40:27,537] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:40:27,583] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:27,594] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,594] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,595] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,597] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,598] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,599] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,604] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,606] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,607] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,616] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,621] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,622] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,624] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,626] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,628] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,629] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,631] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,634] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,643] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@40844aab (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:40:27,674] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:40:27,690] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:27,697] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:27,728] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:27,745] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:60276, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:27,764] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c8154e00003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:40:27,773] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:40:27,946] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:40:28,136] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:40:28,144] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-01-15 11:40:28,215] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:28,255] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:40:28,271] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:40:28,282] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:28,325] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,329] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,330] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,335] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,361] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:40:28,462] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181[2022-01-15 11:40:28,483] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)

	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:28,499] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:40:28,522] INFO Stat of the created znode at /brokers/ids/2 is: 958,958,1642268428507,1642268428507,1,0,0,72124120210341890,214,0,958
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:28,526] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9094, czxid (broker epoch): 958 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:28,606] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:28,609] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:28,609] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:28,615] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:40:28,654] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,665] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,670] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,698] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:28,707] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:28,714] INFO Attempting recovery for all logs in C:\logs\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:40:28,725] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:28,794] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:14000,blockEndProducerId:14999) by writing to Zk with path version 15 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:40:28,797] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:28,806] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:28,806] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:40:28,874] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:28,878] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:28,887] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:28,922] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:40:28,944] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:28,963] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 209ms (1/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:28,977] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:28,987] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:28,991] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:28,995] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,006] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:29,007] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (2/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,008] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:29,019] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:29,023] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,025] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:29,026] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:29,028] INFO Kafka startTimeMs: 1642268429010 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:29,034] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-01-15 11:40:29,048] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,062] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (3/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,078] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:29,084] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,098] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,114] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (4/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,131] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:29,135] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,158] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,170] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-0, topic=my_test_topic2, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (5/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,181] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:29,185] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,209] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,224] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-4, topic=my_test_topic2, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (6/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,237] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:29,240] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,247] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,257] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (7/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,282] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:29,286] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:29,290] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,297] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,305] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 45ms (8/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,319] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:40:29,321] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,329] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:40:29,338] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (9/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:40:29,349] INFO Loaded 9 logs in 641ms. (kafka.log.LogManager)
[2022-01-15 11:40:29,353] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:40:29,356] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:40:29,396] INFO [Partition my_test_topic-2 broker=2] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,403] INFO [Partition my_test_topic3-0 broker=2] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,406] INFO [Partition my_test_topic-0 broker=2] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,411] INFO [Partition my_test_topic2-3 broker=2] Log loaded for partition my_test_topic2-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,412] INFO [Partition my_test_topic3-4 broker=2] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,414] INFO [Partition my_test_topic-4 broker=2] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,416] INFO [Partition my_test_topic3-1 broker=2] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,423] INFO [Partition my_test_topic-1 broker=2] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:29,426] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-1, my_test_topic3-0, my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:29,478] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:29,486] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(my_test_topic3-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),5,0), my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),7,0), my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),5,0), my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),7,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:29,491] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:29,495] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:29,497] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),8,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:29,501] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:29,504] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:29,505] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:29,506] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic3-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:29,509] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:29,511] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:29,516] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:29,519] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:29,520] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:29,559] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic2-3, my_test_topic3-4, my_test_topic3-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:29,564] INFO [Partition my_test_topic-4 broker=0] ISR updated to 0,2 and version updated to [10] (kafka.cluster.Partition)
[2022-01-15 11:40:29,605] INFO [Partition my_test_topic3-0 broker=0] ISR updated to 0,2 and version updated to [7] (kafka.cluster.Partition)
[2022-01-15 11:40:29,606] INFO [Partition my_test_topic-0 broker=0] ISR updated to 0,1,2 and version updated to [11] (kafka.cluster.Partition)
[2022-01-15 11:40:29,609] INFO [Partition my_test_topic-1 broker=0] ISR updated to 0,2 and version updated to [8] (kafka.cluster.Partition)
[2022-01-15 11:40:29,686] INFO [Partition my_test_topic-2 broker=1] ISR updated to 1,2 and version updated to [11] (kafka.cluster.Partition)
[2022-01-15 11:40:30,258] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:40:30,266] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-01-15 11:40:30,357] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:30,419] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:30,463] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:30,471] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:30,472] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:30,471] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:30,509] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:40:30,629] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:30,662] INFO Stat of the created znode at /brokers/ids/3 is: 968,968,1642268430650,1642268430650,1,0,0,72124120210341891,214,0,968
 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:30,664] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9095, czxid (broker epoch): 968 (kafka.zk.KafkaZkClient)
[2022-01-15 11:40:30,806] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:30,823] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:30,826] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:30,879] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:30,940] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 11:40:31,043] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:15000,blockEndProducerId:15999) by writing to Zk with path version 16 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 11:40:31,045] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:31,055] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 11:40:31,056] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 11:40:31,171] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:40:31,236] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 11:40:31,327] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:31,342] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:40:31,343] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 11:40:31,356] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:31,356] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:31,358] INFO Kafka startTimeMs: 1642268431344 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:40:31,371] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-01-15 11:40:31,535] INFO [broker-3-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:40:31,684] INFO [Partition my_test_topic-2 broker=3] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,691] INFO [Partition my_test_topic2-4 broker=3] Log loaded for partition my_test_topic2-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,692] INFO [Partition my_test_topic3-2 broker=3] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,695] INFO [Partition my_test_topic-3 broker=3] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,696] INFO [Partition my_test_topic3-4 broker=3] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,698] INFO [Partition my_test_topic-4 broker=3] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,700] INFO [Partition my_test_topic2-0 broker=3] Log loaded for partition my_test_topic2-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,704] INFO [Partition my_test_topic3-1 broker=3] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,715] INFO [Partition my_test_topic-1 broker=3] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 11:40:31,723] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-1, my_test_topic3-2, my_test_topic-3, my_test_topic3-4, my_test_topic3-1, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:31,828] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,838] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(my_test_topic3-1 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),6,0), my_test_topic3-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),6,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:31,840] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,846] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:31,855] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,855] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,855] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),4,0), my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),7,0), my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),5,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:31,858] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,856] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:31,867] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:31,874] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,875] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(my_test_topic3-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),6,0), my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),8,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:31,881] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,876] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:31,886] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,890] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,892] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:31,899] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:31,904] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic3-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 11:40:31,914] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 11:40:31,958] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic2-4, my_test_topic2-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:40:31,967] INFO [Partition my_test_topic-2 broker=1] ISR updated to 1,2,3 and version updated to [12] (kafka.cluster.Partition)
[2022-01-15 11:40:31,993] INFO [Partition my_test_topic-4 broker=0] ISR updated to 0,2,3 and version updated to [11] (kafka.cluster.Partition)
[2022-01-15 11:40:32,043] INFO [Partition my_test_topic-3 broker=0] ISR updated to 0,1,3 and version updated to [8] (kafka.cluster.Partition)
[2022-01-15 11:40:32,055] INFO [Partition my_test_topic-1 broker=0] ISR updated to 0,2,3 and version updated to [9] (kafka.cluster.Partition)
[2022-01-15 11:40:32,067] INFO [Partition my_test_topic3-2 broker=1] ISR updated to 1,3 and version updated to [8] (kafka.cluster.Partition)
[2022-01-15 11:40:32,093] INFO [Partition my_test_topic3-1 broker=2] ISR updated to 2,3 and version updated to [8] (kafka.cluster.Partition)
[2022-01-15 11:40:32,112] INFO [Partition my_test_topic3-4 broker=2] ISR updated to 2,3 and version updated to [8] (kafka.cluster.Partition)
[2022-01-15 11:43:24,592] WARN Exception causing close of session 0x1003c8154e00000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:43:24,600] WARN Exception causing close of session 0x1003c8154e00001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:43:24,609] WARN Exception causing close of session 0x1003c8154e00002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:43:24,614] WARN Exception causing close of session 0x1003c8154e00003: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 11:49:24,294] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,296] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,312] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,312] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,318] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:49:24,319] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:49:24,319] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 11:49:24,319] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-01-15 11:49:24,326] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-01-15 11:49:24,350] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,351] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,352] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,353] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 11:49:24,353] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-01-15 11:49:24,358] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:49:24,379] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,379] INFO Server environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,379] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,379] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,380] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,380] INFO Server environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,388] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,389] INFO Server environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,392] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,394] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,395] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,397] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,406] INFO Server environment:user.name=Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,407] INFO Server environment:user.home=C:\Users\Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,409] INFO Server environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,411] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,412] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,414] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,419] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,420] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,422] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 snapdir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:24,482] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-01-15 11:49:24,495] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:49:24,512] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 11:49:24,579] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-01-15 11:49:24,589] INFO Reading snapshot C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.35b (org.apache.zookeeper.server.persistence.FileSnap)
[2022-01-15 11:49:24,675] INFO Snapshotting: 0x3d2 to C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.3d2 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 11:49:24,718] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-01-15 11:49:24,728] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2022-01-15 11:49:28,686] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:49:29,737] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:49:29,929] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:49:29,931] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:49:29,969] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:29,977] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,977] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,977] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,977] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,978] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,978] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,983] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,991] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,991] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,992] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,993] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,994] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:29,996] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:30,000] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:30,003] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:30,006] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:30,008] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:30,010] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:30,021] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:30,056] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:49:30,074] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:30,078] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:30,097] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:30,107] INFO Socket connection established, initiating session, client: /127.0.0.1:62307, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:30,126] INFO Creating new log file: log.3d3 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-01-15 11:49:30,146] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c89b9930000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:30,154] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:30,353] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:30,759] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:49:30,812] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:49:30,822] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:49:31,118] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:31,201] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:31,330] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:31,334] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:31,338] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:31,344] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:31,456] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:31,467] INFO Attempting recovery for all logs in C:\logs\kafka-logs-admin since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:49:31,654] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:31,662] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,738] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,763] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\kafkabasics_topic-0, topic=kafkabasics_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 237ms (1/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:31,776] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:31,781] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,796] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,807] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (2/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:31,822] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:31,824] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,841] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,852] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (3/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:31,861] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:31,862] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,875] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,887] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (4/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:31,903] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:31,911] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,929] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,940] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 52ms (5/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:31,955] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:31,957] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,974] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:31,982] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic2-2, topic=my_test_topic2, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (6/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:31,999] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,003] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,018] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,025] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (7/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,037] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,039] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,053] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,061] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (8/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,074] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,077] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,091] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,099] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (9/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,111] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,113] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,127] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,137] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (10/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,162] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,166] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,179] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,189] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 48ms (11/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,200] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,203] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,220] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,227] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (12/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,237] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,239] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,250] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,256] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (13/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,267] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,270] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,287] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,293] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (14/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,310] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,312] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,332] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:49:32,334] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,341] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (15/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,353] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,355] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,371] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,379] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (16/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,389] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,390] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,402] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,410] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (17/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,421] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,424] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,444] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,453] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 42ms (18/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,462] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,465] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,482] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,487] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (19/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,495] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,498] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,511] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,519] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (20/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,528] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,531] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,544] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,553] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (21/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,565] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,569] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,586] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,589] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:49:32,592] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:49:32,594] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (22/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,606] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,609] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,624] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,630] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (23/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,642] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,645] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,674] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,684] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (24/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,699] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,708] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,709] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:32,727] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,732] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,734] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,735] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,735] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,736] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,736] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (25/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,760] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,738] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,793] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,779] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,799] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,802] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,805] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,815] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,817] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,821] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,842] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,842] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,854] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 115ms (26/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:32,875] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,881] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,892] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:32,897] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,906] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,915] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,934] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:32,950] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:32,963] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 87ms (27/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,002] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,009] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:49:33,011] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,051] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:33,062] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,064] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:33,079] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 103ms (28/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,101] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,107] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,114] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:33,133] INFO Socket connection established, initiating session, client: /127.0.0.1:62321, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:33,138] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,152] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (29/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,167] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c89b9930001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:33,174] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,179] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,186] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:33,248] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,263] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 110ms (30/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,288] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,306] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,337] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,353] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 85ms (31/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,378] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,384] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,418] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,440] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 85ms (32/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,460] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,467] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,492] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,502] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 61ms (33/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,519] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,529] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,558] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,569] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 65ms (34/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,595] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,598] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,628] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,650] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 73ms (35/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,673] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,683] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:33,692] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,713] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,744] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 92ms (36/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,778] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,800] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,824] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,828] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 82ms (37/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,843] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,847] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,890] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,905] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 76ms (38/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,943] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:33,950] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,964] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:33,974] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (39/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:33,983] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:49:34,005] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,008] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,029] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,038] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 62ms (40/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,050] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,052] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,072] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,077] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (41/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,088] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,091] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,108] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,113] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (42/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,128] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,130] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,157] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,162] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 48ms (43/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,189] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,191] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,221] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,227] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (44/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,241] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,244] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,260] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,265] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (45/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,274] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,276] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,292] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,295] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (46/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,307] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,309] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,324] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,327] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (47/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,341] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,343] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,359] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,364] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (48/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,381] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,388] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,405] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,408] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (49/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,421] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,423] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,426] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:49:34,445] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,449] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:49:34,456] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (50/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,475] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,477] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,499] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,509] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (51/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,523] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,525] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,539] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,544] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (52/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,556] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,558] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,574] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,577] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (53/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,595] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,598] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,615] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,622] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (54/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,638] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,640] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,657] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,662] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (55/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,673] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,676] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,692] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,702] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (56/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,719] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,735] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,757] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,762] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (57/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,772] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:34,774] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,787] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:34,792] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (58/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 11:49:34,805] INFO Loaded 58 logs in 3349ms. (kafka.log.LogManager)
[2022-01-15 11:49:34,806] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:49:34,811] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:49:34,872] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:34,909] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:35,008] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:35,012] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:35,012] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:35,017] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:35,122] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:49:35,131] INFO Attempting recovery for all logs in C:\logs\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:49:35,272] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:35,278] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,351] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,374] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 209ms (1/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:49:35,388] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:35,391] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,413] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,423] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (2/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:49:35,434] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:35,436] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,448] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,456] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (3/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:49:35,471] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:35,474] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,494] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,504] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic2-1, topic=my_test_topic2, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (4/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:49:35,516] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:35,519] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,531] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,541] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (5/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:49:35,552] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:35,555] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,566] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:35,578] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (6/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 11:49:35,589] INFO Loaded 6 logs in 467ms. (kafka.log.LogManager)
[2022-01-15 11:49:35,591] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:49:35,594] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:49:35,676] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:49:35,877] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:49:35,879] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:49:35,920] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:49:35,928] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:35,930] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-01-15 11:49:35,941] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,942] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,942] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,942] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,943] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,943] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,946] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,951] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,952] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,953] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,955] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,962] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,966] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,967] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,968] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,970] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,972] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,975] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:35,985] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:36,026] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:49:36,037] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:49:36,043] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:36,052] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:36,065] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:36,074] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:62332, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:36,090] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c89b9930002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:36,097] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:36,127] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:36,177] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,184] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,184] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,184] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,214] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:36,305] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:36,375] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:49:36,427] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72124120210341888' does not match current session '72124156259532800' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-01-15 11:49:36,444] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-01-15 11:49:36,454] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:49:36,459] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:36,484] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:36,503] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-01-15 11:49:36,504] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:36,507] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:36,507] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:36,511] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:36,519] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:36,526] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:36,533] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:36,533] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,596] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,596] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,601] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,754] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 11:49:36,756] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:49:36,772] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:49:36,801] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,805] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,801] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,875] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:49:36,886] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-01-15 11:49:36,973] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:49:37,003] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:36,994] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:37,003] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,004] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,035] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:37,060] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:37,102] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,105] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,106] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,106] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,144] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:37,156] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:37,158] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:37,170] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:37,173] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:37,206] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,206] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,223] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-01-15 11:49:37,224] INFO [broker-0-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:37,226] INFO [broker-0-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:37,226] INFO [broker-0-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:37,239] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-01-15 11:49:37,243] INFO Shutting down. (kafka.log.LogManager)
[2022-01-15 11:49:37,314] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,323] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:49:37,325] INFO Attempting recovery for all logs in C:\logs\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:49:37,380] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '72124120210341889' does not match current session '72124156259532801' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-01-15 11:49:37,397] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-01-15 11:49:37,403] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:49:37,406] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:37,418] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:37,429] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-01-15 11:49:37,433] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:37,436] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:37,436] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:37,436] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:37,445] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:37,446] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:37,448] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:37,449] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,532] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,532] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,532] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,540] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,546] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,564] INFO Shutdown complete. (kafka.log.LogManager)
[2022-01-15 11:49:37,569] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:37,573] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:37,573] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:37,580] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:37,618] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,639] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 257ms (1/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,649] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,652] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,659] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,669] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (2/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,677] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,679] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,691] INFO Session: 0x1003c89b9930000 closed (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:37,691] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,691] INFO EventThread shut down for session: 0x1003c89b9930000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:37,697] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:37,707] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:37,706] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (3/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,726] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,729] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,738] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,741] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,743] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,740] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,759] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 48ms (4/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,774] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,776] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,795] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,805] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic2-3, topic=my_test_topic2, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 45ms (5/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,813] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,815] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,824] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,828] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (6/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,837] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,840] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,853] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,860] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (7/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,871] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:37,873] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,885] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:37,892] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (8/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 11:49:37,896] INFO Loaded 8 logs in 580ms. (kafka.log.LogManager)
[2022-01-15 11:49:37,899] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:49:37,903] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:49:37,958] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,958] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:37,961] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:38,107] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 11:49:38,146] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:38,146] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:38,159] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-01-15 11:49:38,160] INFO [broker-1-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:38,161] INFO [broker-1-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:38,161] INFO [broker-1-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:38,191] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-01-15 11:49:38,195] INFO Shutting down. (kafka.log.LogManager)
[2022-01-15 11:49:38,272] INFO Shutdown complete. (kafka.log.LogManager)
[2022-01-15 11:49:38,279] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:38,282] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:38,282] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:38,286] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:38,304] INFO starting (kafka.server.KafkaServer)
[2022-01-15 11:49:38,306] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 11:49:38,342] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:38,353] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,353] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,354] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,354] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,354] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,354] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,358] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,359] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,360] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,361] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,362] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,364] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,373] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,374] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,376] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,378] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,380] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,381] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,389] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,396] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:38,399] INFO Session: 0x1003c89b9930001 closed (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:38,399] INFO EventThread shut down for session: 0x1003c89b9930001 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:38,398] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:38,403] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:38,396] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:38,416] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:38,427] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 11:49:38,447] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:38,454] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:38,469] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:38,476] INFO Socket connection established, initiating session, client: /127.0.0.1:62348, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:38,493] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c89b9930003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:38,501] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:38,658] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:38,910] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:49:38,922] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-01-15 11:49:38,951] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 11:49:38,959] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 11:49:39,001] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:49:39,038] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,038] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,041] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,057] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:39,091] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,094] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,094] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,100] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,125] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:39,142] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:39,172] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 11:49:39,246] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:49:39,254] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,258] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,258] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,264] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,288] ERROR Error while creating ephemeral at /brokers/ids/2, node already exists and owner '72124120210341890' does not match current session '72124156259532802' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-01-15 11:49:39,305] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-01-15 11:49:39,311] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:49:39,314] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:39,326] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:39,337] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-01-15 11:49:39,339] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:39,341] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:39,342] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:39,343] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:39,349] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:39,351] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:39,352] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:39,355] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,382] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,392] INFO Attempting recovery for all logs in C:\logs\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 11:49:39,399] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,399] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,404] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,415] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,415] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,419] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:39,510] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,510] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,511] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,524] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,530] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,576] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,591] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 163ms (1/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,600] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,603] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,609] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,618] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (2/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,623] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,625] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,634] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,639] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (3/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,647] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,650] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,657] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,672] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (4/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,686] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,688] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,709] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,716] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,716] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,722] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-0, topic=my_test_topic2, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 49ms (5/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,723] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,736] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,738] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,753] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,762] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-4, topic=my_test_topic2, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (6/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,775] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,778] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,788] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,792] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (7/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,802] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,804] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,810] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,819] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (8/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,826] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2022-01-15 11:49:39,828] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,837] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 11:49:39,842] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (9/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 11:49:39,847] INFO Loaded 9 logs in 464ms. (kafka.log.LogManager)
[2022-01-15 11:49:39,849] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 11:49:39,852] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 11:49:39,917] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,917] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:39,921] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:40,043] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:40,043] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:40,046] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:40,122] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:40,123] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:40,137] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-01-15 11:49:40,138] INFO [broker-2-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:40,141] INFO [broker-2-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:40,141] INFO [broker-2-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:40,156] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-01-15 11:49:40,160] INFO Shutting down. (kafka.log.LogManager)
[2022-01-15 11:49:40,290] INFO Shutdown complete. (kafka.log.LogManager)
[2022-01-15 11:49:40,291] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:40,293] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:40,293] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:40,300] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:40,420] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:40,421] INFO Session: 0x1003c89b9930002 closed (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:40,420] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:40,425] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-01-15 11:49:40,421] INFO EventThread shut down for session: 0x1003c89b9930002 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:40,424] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:40,441] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:40,499] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-01-15 11:49:40,500] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:40,502] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:40,506] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:40,510] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-01-15 11:49:40,518] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:49:40,520] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-01-15 11:49:40,520] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-01-15 11:49:40,525] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:49:40,798] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 11:49:40,807] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-01-15 11:49:40,885] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 11:49:40,932] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:40,967] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:40,970] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:40,976] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:40,976] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,025] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:41,050] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,050] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,051] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,176] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,178] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 11:49:41,176] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,184] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,191] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,191] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,194] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:41,222] ERROR Error while creating ephemeral at /brokers/ids/3, node already exists and owner '72124120210341891' does not match current session '72124156259532803' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-01-15 11:49:41,236] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-01-15 11:49:41,240] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:49:41,242] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:41,251] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-01-15 11:49:41,260] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-01-15 11:49:41,262] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:41,264] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:41,264] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 11:49:41,266] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:41,271] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-01-15 11:49:41,273] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:41,275] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-01-15 11:49:41,276] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,379] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,379] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,383] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,587] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,587] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,591] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,603] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,603] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,606] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,809] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,809] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 11:49:41,821] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-01-15 11:49:41,822] INFO [broker-3-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:41,824] INFO [broker-3-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:41,824] INFO [broker-3-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 11:49:41,836] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-01-15 11:49:41,839] INFO Shutting down. (kafka.log.LogManager)
[2022-01-15 11:49:41,913] INFO Shutdown complete. (kafka.log.LogManager)
[2022-01-15 11:49:41,913] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:41,916] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:41,916] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 11:49:41,921] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:42,032] INFO Session: 0x1003c89b9930003 closed (org.apache.zookeeper.ZooKeeper)
[2022-01-15 11:49:42,032] INFO EventThread shut down for session: 0x1003c89b9930003 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 11:49:42,037] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 11:49:42,045] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,059] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,059] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,073] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-01-15 11:49:42,132] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-01-15 11:49:42,133] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:42,135] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:42,139] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:42,144] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-01-15 11:49:42,152] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:49:42,153] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-01-15 11:49:42,154] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-01-15 11:49:42,162] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:49:42,202] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,202] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,208] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,281] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,281] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,289] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:42,794] INFO Expiring session 0x1003c8154e00001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:42,795] INFO Expiring session 0x1003c8154e00000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:42,804] INFO Expiring session 0x1003c8154e00002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:42,807] INFO Expiring session 0x1003c8154e00003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 11:49:43,211] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:43,211] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:43,226] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-01-15 11:49:43,285] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-01-15 11:49:43,286] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:43,290] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:43,288] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:43,292] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:43,290] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:43,298] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:43,300] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-01-15 11:49:43,307] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:49:43,308] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-01-15 11:49:43,316] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-01-15 11:49:43,320] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-01-15 11:49:44,294] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:44,294] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:44,303] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:44,310] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:44,310] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 11:49:44,322] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-01-15 11:49:44,384] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-01-15 11:49:44,385] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:44,387] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:44,391] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-01-15 11:49:44,408] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-01-15 11:49:44,417] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 11:49:44,418] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-01-15 11:49:44,420] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-01-15 11:49:44,425] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)

[2022-01-15 12:12:40,122] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,126] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,138] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,138] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,141] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 12:12:40,142] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 12:12:40,151] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-01-15 12:12:40,152] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-01-15 12:12:40,167] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-01-15 12:12:40,213] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,214] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,217] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,217] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-01-15 12:12:40,218] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-01-15 12:12:40,228] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 12:12:40,265] INFO Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,265] INFO Server environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,266] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,267] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,267] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,268] INFO Server environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,275] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,276] INFO Server environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,278] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,280] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,283] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,285] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,307] INFO Server environment:user.name=Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,308] INFO Server environment:user.home=C:\Users\Dagim (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,312] INFO Server environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,316] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,325] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,328] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,338] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,341] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,348] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 snapdir C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-01-15 12:12:40,420] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-01-15 12:12:40,427] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 12:12:40,435] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-01-15 12:12:40,466] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-01-15 12:12:40,481] INFO Reading snapshot C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.3d2 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-01-15 12:12:40,557] INFO Snapshotting: 0x41a to C:\Java_Tools\kafka_2.12-2.8.0\data\zookeeper\version-2\snapshot.41a (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-01-15 12:12:40,617] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-01-15 12:12:40,632] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2022-01-15 12:12:43,774] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 12:12:44,589] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 12:12:44,775] INFO starting (kafka.server.KafkaServer)
[2022-01-15 12:12:44,776] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 12:12:44,815] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:44,825] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,826] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,826] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,826] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,826] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,826] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,830] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,831] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,831] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,833] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,840] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,841] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,843] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,844] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,845] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,846] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,847] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,849] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,856] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:44,879] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 12:12:44,892] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:44,896] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:44,915] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:44,932] INFO Socket connection established, initiating session, client: /127.0.0.1:59727, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:44,962] INFO Creating new log file: log.41b (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-01-15 12:12:44,988] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003c9f06410000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:44,999] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:45,278] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 12:12:45,575] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 12:12:45,585] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 12:12:45,769] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:45,802] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs-admin
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:45,931] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:45,941] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:45,942] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:45,949] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:46,086] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,100] INFO Skipping recovery for all logs in C:\logs\kafka-logs-admin since clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 12:12:46,178] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 12:12:46,339] INFO [Log partition=kafkabasics_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,383] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\kafkabasics_topic-0, topic=kafkabasics_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 204ms (1/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,400] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,412] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (2/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,429] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,441] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (3/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,461] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,473] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (4/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,490] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,499] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (5/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,516] INFO [Log partition=my_test_topic2-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,524] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic2-2, topic=my_test_topic2, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (6/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,551] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,563] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (7/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,591] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,602] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (8/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,650] INFO [Log partition=__consumer_offsets-0, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,675] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 52ms (9/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,731] INFO [Log partition=__consumer_offsets-1, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,758] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 76ms (10/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,796] INFO [Log partition=__consumer_offsets-10, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,807] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (11/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,840] INFO [Log partition=__consumer_offsets-11, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,862] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 49ms (12/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,882] INFO [Log partition=__consumer_offsets-12, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:46,920] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (13/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:46,962] INFO [Log partition=__consumer_offsets-13, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,002] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 70ms (14/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,021] INFO [Log partition=__consumer_offsets-14, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,078] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (15/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,112] INFO [Log partition=__consumer_offsets-15, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,139] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (16/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,156] INFO [Log partition=__consumer_offsets-16, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,165] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (17/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,191] INFO [Log partition=__consumer_offsets-17, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,195] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (18/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,217] INFO [Log partition=__consumer_offsets-18, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,243] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (19/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,267] INFO [Log partition=__consumer_offsets-19, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,281] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (20/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,330] INFO [Log partition=__consumer_offsets-2, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,340] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (21/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,390] INFO [Log partition=__consumer_offsets-20, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,406] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (22/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,435] INFO [Log partition=__consumer_offsets-21, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,447] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (23/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,467] INFO [Log partition=__consumer_offsets-22, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,479] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (24/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,500] INFO [Log partition=__consumer_offsets-23, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,510] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (25/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,558] INFO [Log partition=__consumer_offsets-24, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,590] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 77ms (26/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,613] INFO [Log partition=__consumer_offsets-25, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,627] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (27/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,673] INFO [Log partition=__consumer_offsets-26, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,684] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (28/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,706] INFO [Log partition=__consumer_offsets-27, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,715] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (29/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,737] INFO [Log partition=__consumer_offsets-28, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,751] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (30/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,775] INFO [Log partition=__consumer_offsets-29, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,781] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (31/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,800] INFO [Log partition=__consumer_offsets-3, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,807] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (32/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,828] INFO [Log partition=__consumer_offsets-30, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,835] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (33/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,853] INFO [Log partition=__consumer_offsets-31, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,862] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (34/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,877] INFO [Log partition=__consumer_offsets-32, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,881] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (35/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,895] INFO [Log partition=__consumer_offsets-33, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,899] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (36/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,916] INFO [Log partition=__consumer_offsets-34, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,929] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (37/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,953] INFO [Log partition=__consumer_offsets-35, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,961] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (38/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:47,979] INFO [Log partition=__consumer_offsets-36, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:47,985] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (39/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,001] INFO [Log partition=__consumer_offsets-37, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,005] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (40/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,018] INFO [Log partition=__consumer_offsets-38, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,024] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (41/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,039] INFO [Log partition=__consumer_offsets-39, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,040] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 12:12:48,043] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (42/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,058] INFO [Log partition=__consumer_offsets-4, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,064] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (43/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,083] INFO [Log partition=__consumer_offsets-40, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,091] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (44/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,107] INFO [Log partition=__consumer_offsets-41, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,111] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (45/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,125] INFO [Log partition=__consumer_offsets-42, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,128] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (46/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,150] INFO [Log partition=__consumer_offsets-43, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,156] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (47/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,174] INFO [Log partition=__consumer_offsets-44, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,177] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (48/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,193] INFO [Log partition=__consumer_offsets-45, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,198] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (49/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,211] INFO [Log partition=__consumer_offsets-46, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,215] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (50/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,227] INFO [Log partition=__consumer_offsets-47, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,231] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (51/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,244] INFO [Log partition=__consumer_offsets-48, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,249] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (52/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,261] INFO [Log partition=__consumer_offsets-49, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,265] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (53/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,280] INFO [Log partition=__consumer_offsets-5, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,285] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (54/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,297] INFO starting (kafka.server.KafkaServer)
[2022-01-15 12:12:48,298] INFO [Log partition=__consumer_offsets-6, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,298] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 12:12:48,304] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (55/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,320] INFO [Log partition=__consumer_offsets-7, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,325] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (56/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,340] INFO [Log partition=__consumer_offsets-8, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,351] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (57/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,361] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:48,365] INFO [Log partition=__consumer_offsets-9, dir=C:\logs\kafka-logs-admin] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:48,370] INFO Completed load of Log(dir=C:\logs\kafka-logs-admin\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (58/58 loaded in C:\logs\kafka-logs-admin) (kafka.log.LogManager)
[2022-01-15 12:12:48,378] INFO Loaded 58 logs in 2290ms. (kafka.log.LogManager)
[2022-01-15 12:12:48,378] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,378] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,378] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,380] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,380] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,380] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 12:12:48,386] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 12:12:48,381] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,389] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,390] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,391] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,393] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,395] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,407] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,408] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,410] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,412] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,413] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,415] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,416] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,425] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@40844aab (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:48,470] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 12:12:48,483] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:48,489] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:48,503] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:48,512] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59752, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:48,535] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c9f06410001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:48,544] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:48,721] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 12:12:49,112] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 12:12:49,124] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 12:12:49,357] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:49,412] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:49,453] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 12:12:49,483] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 12:12:49,496] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-01-15 12:12:49,533] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:49,541] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:49,541] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:49,547] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:49,600] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:12:49,714] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 12:12:49,714] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:12:49,730] INFO Skipping recovery for all logs in C:\logs\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 12:12:49,788] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:49,789] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:49,789] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:49,814] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:49,833] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 12:12:49,993] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:50,023] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:50,030] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 249ms (1/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 12:12:50,063] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:50,096] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 51ms (2/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 12:12:50,134] INFO Stat of the created znode at /brokers/ids/0 is: 1081,1081,1642270370101,1642270370101,1,0,0,72124247740317696,214,0,1081
 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:50,137] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:50,139] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9092, czxid (broker epoch): 1081 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:50,164] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (3/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 12:12:50,187] INFO [Log partition=my_test_topic2-1, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:50,230] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic2-1, topic=my_test_topic2, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 64ms (4/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 12:12:50,247] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:50,255] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (5/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 12:12:50,273] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:50,290] INFO Completed load of Log(dir=C:\logs\kafka-logs1\my_test_topic3-3, topic=my_test_topic3, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (6/6 loaded in C:\logs\kafka-logs1) (kafka.log.LogManager)
[2022-01-15 12:12:50,301] INFO Loaded 6 logs in 579ms. (kafka.log.LogManager)
[2022-01-15 12:12:50,304] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 12:12:50,316] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 12:12:50,369] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:50,413] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:50,413] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:50,474] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:50,516] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:50,602] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:16000,blockEndProducerId:16999) by writing to Zk with path version 17 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 12:12:50,611] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:50,623] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:50,648] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 12:12:50,777] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:50,826] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 12:12:50,921] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:12:50,957] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:12:50,962] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:12:50,998] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:51,023] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:51,056] INFO Kafka startTimeMs: 1642270370976 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:51,066] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-01-15 12:12:51,170] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:12:51,330] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, kafkabasics_topic-0, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, my_test_topic3-0, __consumer_offsets-23, __consumer_offsets-49, my_test_topic-3, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, my_test_topic3-3, __consumer_offsets-18, __consumer_offsets-37, my_test_topic2-2, __consumer_offsets-15, __consumer_offsets-24, my_test_topic-4, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, my_test_topic-1, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, my_test_topic-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:51,330] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 12:12:51,372] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,422] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,449] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,472] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,484] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,500] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,516] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,525] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,535] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,543] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,551] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,573] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,591] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,600] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,614] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,637] INFO [Partition kafkabasics_topic-0 broker=0] Log loaded for partition kafkabasics_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,633] INFO starting (kafka.server.KafkaServer)
[2022-01-15 12:12:51,640] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 12:12:51,649] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,669] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,678] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,689] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,698] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,722] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,720] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:51,731] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,738] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,739] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,739] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,741] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,742] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,740] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,743] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,751] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,753] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,757] INFO [Partition my_test_topic-3 broker=0] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,777] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,755] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,794] INFO [Partition my_test_topic2-2 broker=0] Log loaded for partition my_test_topic2-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,790] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,796] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,807] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,799] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,825] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,830] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,832] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,832] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,851] INFO [Partition my_test_topic3-3 broker=0] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,847] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,865] INFO [Partition my_test_topic-0 broker=0] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,858] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,897] INFO [Partition my_test_topic3-0 broker=0] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,925] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,950] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,890] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:51,968] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:51,985] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@42721fe (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:52,040] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,048] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,090] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,103] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,107] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 12:12:52,115] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,125] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,140] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,149] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,144] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:52,159] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,165] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 12:12:52,165] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:52,169] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,180] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,183] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:52,188] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-01-15 12:12:52,191] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,196] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59776, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:52,207] INFO [Partition my_test_topic-4 broker=0] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,223] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,222] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c9f06410002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:52,241] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,245] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:52,249] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,267] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,281] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,292] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,299] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,310] INFO [Partition my_test_topic-1 broker=0] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,323] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,331] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:52,350] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:12:52,365] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,374] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,396] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,400] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,417] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 25 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,435] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,442] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,438] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,445] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,449] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,459] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,461] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,464] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 7 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,462] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:12:52,467] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,469] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 24 milliseconds, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,475] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 17 milliseconds, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,479] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 15 milliseconds, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,483] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 12 milliseconds, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,471] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,485] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,501] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,502] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,506] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,503] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 2 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,524] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,536] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,523] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 17 milliseconds, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,540] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,542] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:52,543] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,547] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,544] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:52,550] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,542] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:52,554] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 12:12:52,543] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:52,543] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 29 milliseconds, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,558] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,581] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,583] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,586] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,588] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,593] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,564] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 40 milliseconds, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,605] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 65 milliseconds, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,602] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,624] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,625] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,627] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,628] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 76 milliseconds, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,630] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,635] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,637] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,640] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,637] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 12:12:52,643] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,663] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,666] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,671] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,673] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,676] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,635] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 75 milliseconds, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,683] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 100 milliseconds, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,678] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,691] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,694] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,689] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 102 milliseconds, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,696] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,710] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,714] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,717] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,703] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 101 milliseconds, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,723] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,734] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,736] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,745] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,748] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,752] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,756] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,760] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,726] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 101 milliseconds, of which 101 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,778] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 150 milliseconds, of which 149 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,761] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,779] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 144 milliseconds, of which 144 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,790] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 158 milliseconds, of which 155 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,807] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 164 milliseconds, of which 161 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,811] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 145 milliseconds, of which 144 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,813] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 140 milliseconds, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,799] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,820] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 142 milliseconds, of which 138 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,856] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 162 milliseconds, of which 161 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,873] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 163 milliseconds, of which 160 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,877] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:52,880] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-01-15 12:12:52,876] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 158 milliseconds, of which 158 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,836] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,893] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,910] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,889] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 154 milliseconds, of which 153 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,916] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 172 milliseconds, of which 172 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,912] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,926] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,938] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,919] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 167 milliseconds, of which 166 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,944] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,946] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,948] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,950] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,945] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 187 milliseconds, of which 187 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,952] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,956] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 195 milliseconds, of which 195 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,964] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,966] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 177 milliseconds, of which 177 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,967] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,972] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,971] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 172 milliseconds, of which 171 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,974] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,977] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 84 milliseconds, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,977] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,983] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,994] INFO Stat of the created znode at /brokers/ids/1 is: 1123,1123,1642270372928,1642270372928,1,0,0,72124247740317697,214,0,1123
 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:52,987] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,999] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:52,996] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9093, czxid (broker epoch): 1123 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:53,004] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,022] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:53,027] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,030] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:53,037] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:52,983] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 72 milliseconds, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,039] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:53,046] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,043] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 116 milliseconds, of which 115 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,061] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 123 milliseconds, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,063] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 119 milliseconds, of which 119 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,101] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 154 milliseconds, of which 124 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,101] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(my_test_topic3-0, my_test_topic-3, my_test_topic3-3, my_test_topic-4, my_test_topic-1, my_test_topic-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:53,105] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 153 milliseconds, of which 153 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 145 milliseconds, of which 144 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 141 milliseconds, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 135 milliseconds, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,121] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 122 milliseconds, of which 120 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,127] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 105 milliseconds, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,133] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 103 milliseconds, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,135] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 97 milliseconds, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 81 milliseconds, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-01-15 12:12:53,228] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 12:12:53,281] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 12:12:53,290] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:53,291] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:53,291] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:53,333] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:53,378] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:53,476] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:17000,blockEndProducerId:17999) by writing to Zk with path version 18 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 12:12:53,478] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:53,490] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:53,499] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 12:12:53,579] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:53,606] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:53,630] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:53,686] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 12:12:53,747] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:12:53,766] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:12:53,767] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:12:53,792] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:53,795] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:53,797] INFO Kafka startTimeMs: 1642270373768 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:53,803] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-01-15 12:12:53,792] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:53,798] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:53,796] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:53,793] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:53,935] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:53,957] INFO Skipping recovery for all logs in C:\logs\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 12:12:54,005] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:12:54,062] INFO [Partition my_test_topic-2 broker=1] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:54,063] INFO [Partition my_test_topic2-1 broker=1] Log loaded for partition my_test_topic2-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:54,070] INFO [Partition my_test_topic3-2 broker=1] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:54,141] INFO [Partition my_test_topic3-3 broker=1] Log loaded for partition my_test_topic3-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:54,145] INFO [Partition my_test_topic-3 broker=1] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:54,147] INFO [Partition my_test_topic-0 broker=1] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:54,152] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic3-3, my_test_topic-3, my_test_topic-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:54,222] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(my_test_topic3-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),3,0), my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),6,0), my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),9,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:54,232] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:54,266] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic3-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:54,274] INFO [Log partition=my_test_topic3-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:54,280] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:54,281] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:54,283] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:54,284] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:54,304] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,308] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic2-1, my_test_topic3-2) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:54,363] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-0, topic=my_test_topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 323ms (1/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,398] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,409] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (2/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,427] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,454] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (3/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,470] INFO [Partition my_test_topic-0 broker=0] ISR updated to 0,1 and version updated to [14] (kafka.cluster.Partition)
[2022-01-15 12:12:54,505] INFO [Partition my_test_topic-3 broker=0] ISR updated to 0,1 and version updated to [11] (kafka.cluster.Partition)
[2022-01-15 12:12:54,496] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,515] INFO [Partition my_test_topic3-3 broker=0] ISR updated to 0,1 and version updated to [6] (kafka.cluster.Partition)
[2022-01-15 12:12:54,532] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 65ms (4/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,549] INFO [Log partition=my_test_topic2-3, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,564] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic2-3, topic=my_test_topic2, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (5/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,600] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,614] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-0, topic=my_test_topic3, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 46ms (6/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,630] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,641] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (7/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,680] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:54,695] INFO Completed load of Log(dir=C:\logs\kafka-logs2\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (8/8 loaded in C:\logs\kafka-logs2) (kafka.log.LogManager)
[2022-01-15 12:12:54,709] INFO Loaded 8 logs in 763ms. (kafka.log.LogManager)
[2022-01-15 12:12:54,712] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 12:12:54,715] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 12:12:54,772] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-01-15 12:12:54,987] INFO starting (kafka.server.KafkaServer)
[2022-01-15 12:12:54,991] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-01-15 12:12:55,056] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:55,068] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,069] INFO Client environment:host.name=DESKTOP-1UO7TTD (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,069] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,070] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,070] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.11 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,070] INFO Client environment:java.class.path=C:\Java_Tools\kafka_2.12-2.8.0\libs\activation-1.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\aopalliance-repackaged-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\argparse4j-0.7.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\audience-annotations-0.5.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-cli-1.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\commons-lang3-3.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-api-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-basic-auth-extension-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-file-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-json-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-mirror-client-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-runtime-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\connect-transforms-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-api-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-locator-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\hk2-utils-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-core-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-databind-2.10.5.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-dataformat-csv-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-datatype-jdk8-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-base-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-jaxrs-json-provider-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-jaxb-annotations-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-paranamer-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jackson-module-scala_2.12-2.10.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.activation-api-1.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.annotation-api-1.3.5.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.inject-2.6.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.validation-api-2.0.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javassist-3.27.0-GA.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.servlet-api-3.1.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jaxb-api-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-client-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-common-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-container-servlet-core-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-hk2-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-media-jaxb-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jersey-server-2.31.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-client-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-continuation-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-http-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-io-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-security-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-server-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlet-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-servlets-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jetty-util-ajax-9.4.39.v20210325.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jline-3.12.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\jopt-simple-5.0.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-clients-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-log4j-appender-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-metadata-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-raft-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-shell-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-examples-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-scala_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-streams-test-utils-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka-tools-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-javadoc.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test-sources.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0-test.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\kafka_2.12-2.8.0.jar.asc;C:\Java_Tools\kafka_2.12-2.8.0\libs\log4j-1.2.17.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\lz4-java-1.7.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\maven-artifact-3.6.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\metrics-core-2.2.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-buffer-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-codec-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-handler-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-resolver-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-epoll-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\netty-transport-native-unix-common-4.1.62.Final.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\osgi-resource-locator-1.0.3.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\paranamer-2.8.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\plexus-utils-3.2.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\reflections-0.9.12.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\rocksdbjni-5.18.4.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-collection-compat_2.12-2.3.0.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-java8-compat_2.12-0.9.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-library-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-logging_2.12-3.9.2.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\scala-reflect-2.12.13.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-api-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\slf4j-log4j12-1.7.30.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\snappy-java-1.1.8.1.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zookeeper-jute-3.5.9.jar;C:\Java_Tools\kafka_2.12-2.8.0\libs\zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,075] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.11\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Java_Tools\apache-cassandra-3.11.10\bin;C:\Python27;;C:\Program Files\Cloud Foundry;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Amazon\AWSCLIV2\;C:\Users\Dagim\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk-11.0.11\bin;C:\Java_Tools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin;%GIT_HOME%\bin;C:\Users\Dagim\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Dagim\AppData\Roaming\npm;C:\Java_Tools\bosh\;;. (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,076] INFO Client environment:java.io.tmpdir=C:\Users\Dagim\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,077] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,079] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,080] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,082] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,092] INFO Client environment:user.name=Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,093] INFO Client environment:user.home=C:\Users\Dagim (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,095] INFO Client environment:user.dir=C:\Java_Tools\kafka_2.12-2.8.0 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,097] INFO Client environment:os.memory.free=1011MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,098] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,100] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,110] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1f6c9cd8 (org.apache.zookeeper.ZooKeeper)
[2022-01-15 12:12:55,159] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-01-15 12:12:55,179] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:55,184] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:55,200] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:55,212] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59803, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:55,233] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003c9f06410003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-01-15 12:12:55,247] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-01-15 12:12:55,507] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-01-15 12:12:55,943] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-01-15 12:12:55,964] INFO Cluster ID = n5bNLnLkQfaSYZqIzTrsvg (kafka.server.KafkaServer)
[2022-01-15 12:12:56,005] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 12:12:56,018] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-01-15 12:12:56,134] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:12:56,216] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:12:56,219] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:56,267] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:56,260] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /logs/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-01-15 12:12:56,277] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:56,278] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:56,278] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:56,326] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 12:12:56,393] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:56,398] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:56,403] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:56,409] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-01-15 12:12:56,488] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:56,544] INFO Stat of the created znode at /brokers/ids/2 is: 1146,1146,1642270376531,1642270376531,1,0,0,72124247740317698,214,0,1146
 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:56,544] INFO Loading logs from log dirs ArrayBuffer(C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:56,566] INFO Skipping recovery for all logs in C:\logs\kafka-logs3 since clean shutdown file was found (kafka.log.LogManager)
[2022-01-15 12:12:56,554] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9094, czxid (broker epoch): 1146 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:56,816] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:56,875] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-1, topic=my_test_topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 228ms (1/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:56,921] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:56,927] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:56,922] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:56,944] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:56,937] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:56,957] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-2, topic=my_test_topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (2/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:56,980] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:56,996] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-3, topic=my_test_topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (3/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:57,009] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:57,027] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:57,064] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic-4, topic=my_test_topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (4/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:57,078] INFO [Log partition=my_test_topic2-0, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:57,095] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-0, topic=my_test_topic2, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (5/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:57,111] INFO [Log partition=my_test_topic2-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:57,122] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic2-4, topic=my_test_topic2, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (6/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:57,143] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:57,166] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:18000,blockEndProducerId:18999) by writing to Zk with path version 19 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 12:12:57,170] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:57,161] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-1, topic=my_test_topic3, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (7/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:57,195] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:57,200] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 12:12:57,208] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:57,219] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-2, topic=my_test_topic3, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (8/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:57,242] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-01-15 12:12:57,250] INFO Completed load of Log(dir=C:\logs\kafka-logs3\my_test_topic3-4, topic=my_test_topic3, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (9/9 loaded in C:\logs\kafka-logs3) (kafka.log.LogManager)
[2022-01-15 12:12:57,290] INFO Loaded 9 logs in 735ms. (kafka.log.LogManager)
[2022-01-15 12:12:57,293] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-01-15 12:12:57,298] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-01-15 12:12:57,339] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:57,392] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 12:12:57,480] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:12:57,510] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:12:57,511] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:12:57,524] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:57,525] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:57,527] INFO Kafka startTimeMs: 1642270377512 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:12:57,536] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-01-15 12:12:57,757] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:12:57,880] INFO [Partition my_test_topic-2 broker=2] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,890] INFO [Partition my_test_topic3-0 broker=2] Log loaded for partition my_test_topic3-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,895] INFO [Partition my_test_topic-0 broker=2] Log loaded for partition my_test_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,902] INFO [Partition my_test_topic2-3 broker=2] Log loaded for partition my_test_topic2-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,916] INFO [Partition my_test_topic3-4 broker=2] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,921] INFO [Partition my_test_topic-4 broker=2] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,927] INFO [Partition my_test_topic3-1 broker=2] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,935] INFO [Partition my_test_topic-1 broker=2] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:12:57,939] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-1, my_test_topic3-0, my_test_topic-0, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:58,021] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:58,028] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(my_test_topic3-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),6,0), my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),9,0), my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),7,0), my_test_topic-0 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),9,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:58,061] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:58,074] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:58,076] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),12,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:58,100] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic3-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:58,104] INFO [Log partition=my_test_topic3-0, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:58,108] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:58,122] INFO [Log partition=my_test_topic-0, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:58,126] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:58,129] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:58,091] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:58,134] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:12:58,134] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:12:58,236] INFO [Partition my_test_topic-4 broker=0] ISR updated to 0,2 and version updated to [14] (kafka.cluster.Partition)
[2022-01-15 12:12:58,225] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my_test_topic2-3, my_test_topic3-4, my_test_topic3-1) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:12:58,301] INFO [Partition my_test_topic3-0 broker=0] ISR updated to 0,2 and version updated to [9] (kafka.cluster.Partition)
[2022-01-15 12:12:58,312] INFO [Partition my_test_topic-0 broker=0] ISR updated to 0,1,2 and version updated to [15] (kafka.cluster.Partition)
[2022-01-15 12:12:58,363] INFO [Partition my_test_topic-2 broker=1] ISR updated to 1,2 and version updated to [17] (kafka.cluster.Partition)
[2022-01-15 12:12:58,371] INFO [Partition my_test_topic-1 broker=0] ISR updated to 0,2 and version updated to [12] (kafka.cluster.Partition)
[2022-01-15 12:12:58,968] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-01-15 12:12:58,984] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-01-15 12:12:59,104] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:12:59,185] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:12:59,236] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,237] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,246] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,246] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,279] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-01-15 12:12:59,395] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:59,427] INFO Stat of the created znode at /brokers/ids/3 is: 1156,1156,1642270379413,1642270379413,1,0,0,72124247740317699,214,0,1156
 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:59,430] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://DESKTOP-1UO7TTD:9095, czxid (broker epoch): 1156 (kafka.zk.KafkaZkClient)
[2022-01-15 12:12:59,607] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,624] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,626] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,665] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:59,692] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-01-15 12:12:59,780] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:19000,blockEndProducerId:19999) by writing to Zk with path version 20 (kafka.coordinator.transaction.ProducerIdManager)
[2022-01-15 12:12:59,786] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:59,795] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-01-15 12:12:59,799] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-01-15 12:12:59,892] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-01-15 12:12:59,954] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-01-15 12:13:00,010] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:13:00,031] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-01-15 12:13:00,034] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-01-15 12:13:00,049] INFO Kafka version: 2.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:13:00,050] INFO Kafka commitId: ebb1d6e21cc92130 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:13:00,054] INFO Kafka startTimeMs: 1642270380035 (org.apache.kafka.common.utils.AppInfoParser)
[2022-01-15 12:13:00,063] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-01-15 12:13:00,274] INFO [broker-3-to-controller-send-thread]: Recorded new controller, from now on will use broker DESKTOP-1UO7TTD:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-01-15 12:13:00,347] INFO [Partition my_test_topic-2 broker=3] Log loaded for partition my_test_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,356] INFO [Partition my_test_topic2-4 broker=3] Log loaded for partition my_test_topic2-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,357] INFO [Partition my_test_topic3-2 broker=3] Log loaded for partition my_test_topic3-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,360] INFO [Partition my_test_topic-3 broker=3] Log loaded for partition my_test_topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,362] INFO [Partition my_test_topic3-4 broker=3] Log loaded for partition my_test_topic3-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,364] INFO [Partition my_test_topic-4 broker=3] Log loaded for partition my_test_topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,372] INFO [Partition my_test_topic2-0 broker=3] Log loaded for partition my_test_topic2-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,376] INFO [Partition my_test_topic3-1 broker=3] Log loaded for partition my_test_topic3-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,381] INFO [Partition my_test_topic-1 broker=3] Log loaded for partition my_test_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-01-15 12:13:00,392] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic-2, my_test_topic-1, my_test_topic3-2, my_test_topic-3, my_test_topic3-4, my_test_topic3-1, my_test_topic-4) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:13:00,458] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,466] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(my_test_topic3-1 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),9,0), my_test_topic3-4 -> InitialFetchState(BrokerEndPoint(id=2, host=DESKTOP-1UO7TTD:9094),9,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:13:00,470] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,478] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(my_test_topic-3 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),6,0), my_test_topic-4 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),9,0), my_test_topic-1 -> InitialFetchState(BrokerEndPoint(id=0, host=DESKTOP-1UO7TTD:9092),7,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:13:00,479] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,481] INFO [Log partition=my_test_topic3-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:13:00,483] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,489] INFO [Log partition=my_test_topic-1, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:13:00,491] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition my_test_topic3-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,491] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(my_test_topic3-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),9,0), my_test_topic-2 -> InitialFetchState(BrokerEndPoint(id=1, host=DESKTOP-1UO7TTD:9093),12,0)) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:13:00,499] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,503] INFO [Log partition=my_test_topic-3, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:13:00,499] INFO [Log partition=my_test_topic3-1, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:13:00,498] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,506] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition my_test_topic-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,510] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,514] INFO [Log partition=my_test_topic-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:13:00,513] INFO [Log partition=my_test_topic-4, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:13:00,518] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition my_test_topic3-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-01-15 12:13:00,528] INFO [Log partition=my_test_topic3-2, dir=C:\logs\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-01-15 12:13:00,597] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(my_test_topic2-4, my_test_topic2-0) (kafka.server.ReplicaFetcherManager)
[2022-01-15 12:13:00,601] INFO [Partition my_test_topic-4 broker=0] ISR updated to 0,2,3 and version updated to [15] (kafka.cluster.Partition)
[2022-01-15 12:13:00,628] INFO [Partition my_test_topic-2 broker=1] ISR updated to 1,2,3 and version updated to [18] (kafka.cluster.Partition)
[2022-01-15 12:13:00,654] INFO [Partition my_test_topic-3 broker=0] ISR updated to 0,1,3 and version updated to [12] (kafka.cluster.Partition)
[2022-01-15 12:13:00,662] INFO [Partition my_test_topic-1 broker=0] ISR updated to 0,2,3 and version updated to [13] (kafka.cluster.Partition)
[2022-01-15 12:13:00,675] INFO [Partition my_test_topic3-2 broker=1] ISR updated to 1,3 and version updated to [12] (kafka.cluster.Partition)
[2022-01-15 12:13:00,733] INFO [Partition my_test_topic3-1 broker=2] ISR updated to 2,3 and version updated to [12] (kafka.cluster.Partition)
[2022-01-15 12:13:00,749] INFO [Partition my_test_topic3-4 broker=2] ISR updated to 2,3 and version updated to [12] (kafka.cluster.Partition)
[2022-01-15 12:15:29,085] WARN Exception causing close of session 0x1003c9f06410000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 12:15:29,088] WARN Exception causing close of session 0x1003c9f06410001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 12:15:29,089] WARN Exception causing close of session 0x1003c9f06410002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2022-01-15 12:15:29,095] WARN Exception causing close of session 0x1003c9f06410003: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
